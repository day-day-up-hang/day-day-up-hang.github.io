<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="unique_Hang&#39;s blog">
<meta property="og:url" content="http://example.com/page/3/index.html">
<meta property="og:site_name" content="unique_Hang&#39;s blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="unique_Hang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>unique_Hang's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">unique_Hang's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/05/Unet%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="unique_Hang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="unique_Hang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/05/Unet%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/" class="post-title-link" itemprop="url">Unet语义分割</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-05 14:51:22" itemprop="dateCreated datePublished" datetime="2022-04-05T14:51:22+08:00">2022-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-06 14:24:49" itemprop="dateModified" datetime="2022-04-06T14:24:49+08:00">2022-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <meta name="referrer" content="no-referrer" /> 

<p>Welcome to unique_Hang’s blog.</p>
<blockquote>
<p><strong>鲁迅说过：看unique_Hang博客的人颜值都很高！</strong><br> 作者邮箱：<a href="mailto:unique_hang@qq.com">unique_hang@qq.com</a><br>喜欢的小伙伴可以关注我的<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">b站账号</a>(<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">https://space.bilibili.com/290100464</a>)  </p>
</blockquote>
<p>原文网址：<a target="_blank" rel="noopener" href="http://www.arxiv.org/pdf/1505.04597.pdf">http://www.arxiv.org/pdf/1505.04597.pdf</a></p>
<p>Unet可以分为三个部分，如下图所示：</p>
<p>第一部分是<strong>主干特征提取部分</strong>，我们可以利用主干部分获得一个又一个的<strong>特征层</strong>，Unet的主干特征提取部分与VGG相似，为卷积和最大池化的堆叠。<strong>利用主干特征提取部分我们可以获得五个初步有效特征层</strong>，在第二步中，我们会利用这五个有效特征层可以进行特征融合。</p>
<p>第二部分是<strong>加强特征提取部分</strong>，我们可以利用主干部分获取到的五个初步有效特征层进行上采样，并且进行特征融合，获得一个最终的，融合了所有特征的有效特征层。</p>
<p>第三部分是<strong>预测部分</strong>，我们会利用最终获得的最后一个有效特征层对每一个特征点进行分类，相当于对每一个像素点进行分类。</p>
<p><img src="https://wx1.sinaimg.cn/mw1024/007BSstUly1gosnf204c5j310f0n7tgz.jpg"></p>
<p>原论文的一些细节：</p>
<ul>
<li><p>原文：The cropping is necessary due to the loss of border pixels in every convolution.</p>
<p>得到信息：<strong>得到图片的大小略小于原图</strong>，从图中可以看到输入图片大小（572 x 572），输出图片大小（388 x 388）</p>
</li>
<li><p>原文：To minimize the overhead and make maximum use of the GPU memory, we favor large  input tiles over a large batch size and hence reduce the batch to a single  image.</p>
<p>得到信息：<strong>batch  &#x3D; 1</strong></p>
</li>
<li><p>原文：Accordingly we use a high momentum (0.99) such that a large number of the  previously seen training samples determine the update in the current  optimization step.</p>
<p>得到信息：<strong>动量v&#x3D;0.99</strong></p>
</li>
<li><p>原文：</p>
</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/05/Unet%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="unique_Hang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="unique_Hang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/05/Unet%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">Unet使用方法</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-05 14:49:53" itemprop="dateCreated datePublished" datetime="2022-04-05T14:49:53+08:00">2022-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-06 14:24:42" itemprop="dateModified" datetime="2022-04-06T14:24:42+08:00">2022-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <meta name="referrer" content="no-referrer" /> 

<p>Welcome to unique_Hang’s blog.</p>
<blockquote>
<p><strong>鲁迅说过：看unique_Hang博客的人颜值都很高！</strong><br> 作者邮箱：<a href="mailto:unique_hang@qq.com">unique_hang@qq.com</a><br>喜欢的小伙伴可以关注我的<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">b站账号</a>(<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">https://space.bilibili.com/290100464</a>)  </p>
</blockquote>
<h1 id="自己训练数据集步骤"><a href="#自己训练数据集步骤" class="headerlink" title="自己训练数据集步骤"></a>自己训练数据集步骤</h1><ol>
<li><p>准备数据集图片，放入.\datasets\before文件夹，打开labelme（版本：3.16.7）进行标注。</p>
</li>
<li><p>打开json_to_dataset.py，修改classes &#x3D; [“<em>background</em>“,”cat”,”dog”]，第一个背景参数不变，把其他的改为需要分的类。运行该脚本，会生成.&#x2F;datasets&#x2F;JPEGImages文件夹存放原始图片，在datasets&#x2F;SegmentationClass文件夹存放掩图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line">import base64</span><br><span class="line">import json</span><br><span class="line">import os</span><br><span class="line">import os.path as osp</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">import PIL.Image</span><br><span class="line">import yaml</span><br><span class="line">from labelme import utils</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def mkdir(path):</span><br><span class="line">    folder = os.path.exists(path)</span><br><span class="line"></span><br><span class="line">    if not folder:  # 判断是否存在文件夹如果不存在则创建为文件夹</span><br><span class="line">        os.makedirs(path)  # makedirs 创建文件时如果路径不存在会创建这个路径</span><br><span class="line">        print(&#x27;环境配置完毕！&#x27;)</span><br><span class="line">    else:</span><br><span class="line">        print(&#x27;环境检测完毕！&#x27;)</span><br><span class="line"></span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">我使用的labelme版本是3.16.7，建议使用该版本的labelme，有些版本的labelme会发生错误</span><br><span class="line">此处生成的标签图是8位彩色图，每个像素点的值就是这个像素点所属的种类</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    mkdir(&quot;datasets/JPEGImages&quot;)</span><br><span class="line">    mkdir(&quot;datasets/SegmentationClass&quot;)</span><br><span class="line">    jpgs_path = &quot;datasets/JPEGImages&quot;</span><br><span class="line">    pngs_path = &quot;datasets/SegmentationClass&quot;</span><br><span class="line">    #classes = [&quot;_background_&quot;,&quot;aeroplane&quot;, &quot;bicycle&quot;, &quot;bird&quot;, &quot;boat&quot;, &quot;bottle&quot;, &quot;bus&quot;, &quot;car&quot;, &quot;cat&quot;, &quot;chair&quot;, &quot;cow&quot;, &quot;diningtable&quot;, &quot;dog&quot;, &quot;horse&quot;, &quot;motorbike&quot;, &quot;person&quot;, &quot;pottedplant&quot;, &quot;sheep&quot;, &quot;sofa&quot;, &quot;train&quot;, &quot;tvmonitor&quot;]</span><br><span class="line">    # classes = [&quot;_background_&quot;,&quot;cat&quot;,&quot;dog&quot;]</span><br><span class="line">    classes = [&quot;_background_&quot;, &quot;1&quot;]</span><br><span class="line">    </span><br><span class="line">    count = os.listdir(&quot;./datasets/before/&quot;) </span><br><span class="line">    for i in range(0, len(count)):</span><br><span class="line">        path = os.path.join(&quot;./datasets/before&quot;, count[i])</span><br><span class="line"></span><br><span class="line">        if os.path.isfile(path) and path.endswith(&#x27;json&#x27;):</span><br><span class="line">            data = json.load(open(path))</span><br><span class="line">            </span><br><span class="line">            if data[&#x27;imageData&#x27;]:</span><br><span class="line">                imageData = data[&#x27;imageData&#x27;]</span><br><span class="line">            else:</span><br><span class="line">                imagePath = os.path.join(os.path.dirname(path), data[&#x27;imagePath&#x27;])</span><br><span class="line">                with open(imagePath, &#x27;rb&#x27;) as f:</span><br><span class="line">                    imageData = f.read()</span><br><span class="line">                    imageData = base64.b64encode(imageData).decode(&#x27;utf-8&#x27;)</span><br><span class="line"></span><br><span class="line">            img = utils.img_b64_to_arr(imageData)</span><br><span class="line">            label_name_to_value = &#123;&#x27;_background_&#x27;: 0&#125;</span><br><span class="line">            for shape in data[&#x27;shapes&#x27;]:</span><br><span class="line">                label_name = shape[&#x27;label&#x27;]</span><br><span class="line">                if label_name in label_name_to_value:</span><br><span class="line">                    label_value = label_name_to_value[label_name]</span><br><span class="line">                else:</span><br><span class="line">                    label_value = len(label_name_to_value)</span><br><span class="line">                    label_name_to_value[label_name] = label_value</span><br><span class="line">            </span><br><span class="line">            # label_values must be dense</span><br><span class="line">            label_values, label_names = [], []</span><br><span class="line">            for ln, lv in sorted(label_name_to_value.items(), key=lambda x: x[1]):</span><br><span class="line">                label_values.append(lv)</span><br><span class="line">                label_names.append(ln)</span><br><span class="line">            assert label_values == list(range(len(label_values)))</span><br><span class="line">            </span><br><span class="line">            lbl = utils.shapes_to_label(img.shape, data[&#x27;shapes&#x27;], label_name_to_value)</span><br><span class="line">            </span><br><span class="line">                </span><br><span class="line">            PIL.Image.fromarray(img).save(osp.join(jpgs_path, count[i].split(&quot;.&quot;)[0]+&#x27;.jpg&#x27;))</span><br><span class="line"></span><br><span class="line">            new = np.zeros([np.shape(img)[0],np.shape(img)[1]])</span><br><span class="line">            for name in label_names:</span><br><span class="line">                index_json = label_names.index(name)</span><br><span class="line">                index_all = classes.index(name)</span><br><span class="line">                new = new + index_all*(np.array(lbl) == index_json)</span><br><span class="line"></span><br><span class="line">            utils.lblsave(osp.join(pngs_path, count[i].split(&quot;.&quot;)[0]+&#x27;.png&#x27;), new)</span><br><span class="line">            print(&#x27;Saved &#x27; + count[i].split(&quot;.&quot;)[0] + &#x27;.jpg and &#x27; + count[i].split(&quot;.&quot;)[0] + &#x27;.png&#x27;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>


</li>
<li><p>把JPEGImages文件夹和SegmentationClass文件夹复制到VOCdevkit&#x2F;VOC2007中，运行voc2unet.py，生成txt文件（存放在.\VOCdevkit\VOC2007\ImageSets\Segmentation）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import random </span><br><span class="line">random.seed(0)</span><br><span class="line"> </span><br><span class="line">segfilepath=r&#x27;./VOC2007/SegmentationClass&#x27;</span><br><span class="line">saveBasePath=r&quot;./VOC2007/ImageSets/Segmentation/&quot;</span><br><span class="line"> </span><br><span class="line">#----------------------------------------------------------------------#</span><br><span class="line">#   想要增加测试集修改trainval_percent</span><br><span class="line">#   修改train_percent用于改变验证集的比例</span><br><span class="line">#----------------------------------------------------------------------#</span><br><span class="line">trainval_percent=1</span><br><span class="line">train_percent=0.9</span><br><span class="line"></span><br><span class="line">temp_seg = os.listdir(segfilepath)</span><br><span class="line">total_seg = []</span><br><span class="line">for seg in temp_seg:</span><br><span class="line">    if seg.endswith(&quot;.png&quot;):</span><br><span class="line">        total_seg.append(seg)</span><br><span class="line"></span><br><span class="line">num=len(total_seg)  </span><br><span class="line">list=range(num)  </span><br><span class="line">tv=int(num*trainval_percent)  </span><br><span class="line">tr=int(tv*train_percent)  </span><br><span class="line">trainval= random.sample(list,tv)  </span><br><span class="line">train=random.sample(trainval,tr)  </span><br><span class="line"> </span><br><span class="line">print(&quot;train and val size&quot;,tv)</span><br><span class="line">print(&quot;traub suze&quot;,tr)</span><br><span class="line">ftrainval = open(os.path.join(saveBasePath,&#x27;trainval.txt&#x27;), &#x27;w&#x27;)  </span><br><span class="line">ftest = open(os.path.join(saveBasePath,&#x27;test.txt&#x27;), &#x27;w&#x27;)  </span><br><span class="line">ftrain = open(os.path.join(saveBasePath,&#x27;train.txt&#x27;), &#x27;w&#x27;)  </span><br><span class="line">fval = open(os.path.join(saveBasePath,&#x27;val.txt&#x27;), &#x27;w&#x27;)  </span><br><span class="line"> </span><br><span class="line">for i  in list:  </span><br><span class="line">    name=total_seg[i][:-4]+&#x27;\n&#x27;  </span><br><span class="line">    if i in trainval:  </span><br><span class="line">        ftrainval.write(name)  </span><br><span class="line">        if i in train:  </span><br><span class="line">            ftrain.write(name)  </span><br><span class="line">        else:  </span><br><span class="line">            fval.write(name)  </span><br><span class="line">    else:  </span><br><span class="line">        ftest.write(name)  </span><br><span class="line">  </span><br><span class="line">ftrainval.close()  </span><br><span class="line">ftrain.close()  </span><br><span class="line">fval.close()  </span><br><span class="line">ftest .close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>运行train.py进行训练，修改num_classes参数，设置成 类别个数+1（背景类）</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import tensorflow as tf</span><br><span class="line">import tensorflow.keras</span><br><span class="line">import numpy as np</span><br><span class="line">from tensorflow.keras import backend as K</span><br><span class="line">from tensorflow.keras.callbacks import (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau,</span><br><span class="line">                             TensorBoard)</span><br><span class="line">from tensorflow.keras.metrics import categorical_accuracy</span><br><span class="line">from tensorflow.keras.optimizers import Adam</span><br><span class="line">from keras.utils.data_utils import get_file</span><br><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">from nets.unet import Unet</span><br><span class="line">from nets.unet_training import CE, Generator, dice_loss_with_CE</span><br><span class="line">from utils.metrics import Iou_score, f_score</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:    </span><br><span class="line">    log_dir = &quot;logs\\&quot;</span><br><span class="line">    #------------------------------#</span><br><span class="line">    #   输入图片的大小</span><br><span class="line">    #------------------------------#</span><br><span class="line">    inputs_size = [512,512,3]</span><br><span class="line">    #------------------------------#</span><br><span class="line">    #   分类个数+1</span><br><span class="line">    #   2+1</span><br><span class="line">    #------------------------------#</span><br><span class="line">    num_classes = 2</span><br><span class="line">    #--------------------------------------------------------------------#</span><br><span class="line">    #   建议选项：</span><br><span class="line">    #   种类少（几类）时，设置为True</span><br><span class="line">    #   种类多（十几类）时，如果batch_size比较大（10以上），那么设置为True</span><br><span class="line">    #   种类多（十几类）时，如果batch_size比较小（10以下），那么设置为False</span><br><span class="line">    #---------------------------------------------------------------------# </span><br><span class="line">    dice_loss = True</span><br><span class="line"></span><br><span class="line">    # 获取model</span><br><span class="line">    model = Unet(inputs_size,num_classes)</span><br><span class="line"></span><br><span class="line">    #-------------------------------------------#</span><br><span class="line">    #   权值文件的下载请看README</span><br><span class="line">    #   权值和主干特征提取网络一定要对应</span><br><span class="line">    #-------------------------------------------#</span><br><span class="line">    #model_path = &quot;./model_data/unet_voc.h5&quot;</span><br><span class="line">    #model.load_weights(model_path, by_name=True, skip_mismatch=True)</span><br><span class="line"></span><br><span class="line">    # 打开数据集的txt</span><br><span class="line">    with open(r&quot;VOCdevkit/VOC2007/ImageSets/Segmentation/train.txt&quot;,&quot;r&quot;) as f:</span><br><span class="line">        train_lines = f.readlines()</span><br><span class="line"></span><br><span class="line">    # 打开数据集的txt</span><br><span class="line">    with open(r&quot;VOCdevkit/VOC2007/ImageSets/Segmentation/val.txt&quot;,&quot;r&quot;) as f:</span><br><span class="line">        val_lines = f.readlines()</span><br><span class="line">        </span><br><span class="line">    #-------------------------------------------------------------------------------#</span><br><span class="line">    #   训练参数的设置</span><br><span class="line">    #   logging表示tensorboard的保存地址</span><br><span class="line">    #   checkpoint用于设置权值保存的细节，period用于修改多少epoch保存一次</span><br><span class="line">    #   reduce_lr用于设置学习率下降的方式</span><br><span class="line">    #   early_stopping用于设定早停，val_loss多次不下降自动结束训练，表示模型基本收敛</span><br><span class="line">    #-------------------------------------------------------------------------------#</span><br><span class="line">    checkpoint_period = ModelCheckpoint(log_dir + &#x27;ep&#123;epoch:03d&#125;-loss&#123;loss:.3f&#125;-val_loss&#123;val_loss:.3f&#125;.h5&#x27;,</span><br><span class="line">                                    monitor=&#x27;val_loss&#x27;, save_weights_only=True, save_best_only=False, period=1)</span><br><span class="line">    reduce_lr = ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;, factor=0.5, patience=3, verbose=1)</span><br><span class="line">    early_stopping = EarlyStopping(monitor=&#x27;val_loss&#x27;, min_delta=0, patience=10, verbose=1)</span><br><span class="line">    tensorboard = TensorBoard(log_dir=log_dir)</span><br><span class="line"></span><br><span class="line">    freeze_layers = 17</span><br><span class="line"></span><br><span class="line">    for i in range(freeze_layers): model.layers[i].trainable = False</span><br><span class="line">    print(&#x27;Freeze the first &#123;&#125; layers of total &#123;&#125; layers.&#x27;.format(freeze_layers, len(model.layers)))</span><br><span class="line"></span><br><span class="line">    #------------------------------------------------------#</span><br><span class="line">    #   主干特征提取网络特征通用，冻结训练可以加快训练速度</span><br><span class="line">    #   也可以在训练初期防止权值被破坏。</span><br><span class="line">    #   Init_Epoch为起始世代</span><br><span class="line">    #   Freeze_Epoch为冻结训练的世代</span><br><span class="line">    #   Epoch总训练世代</span><br><span class="line">    #   提示OOM或者显存不足请调小Batch_size</span><br><span class="line">    #------------------------------------------------------#</span><br><span class="line">    if True:</span><br><span class="line">        lr = 1e-4</span><br><span class="line">        Init_Epoch = 0</span><br><span class="line">        Freeze_Epoch = 50</span><br><span class="line">        Batch_size = 2</span><br><span class="line"></span><br><span class="line">        model.compile(loss = dice_loss_with_CE() if dice_loss else CE(),</span><br><span class="line">                optimizer = Adam(lr=lr),</span><br><span class="line">                metrics = [f_score()])</span><br><span class="line">        print(&#x27;Train on &#123;&#125; samples, val on &#123;&#125; samples, with batch size &#123;&#125;.&#x27;.format(len(train_lines), len(val_lines), Batch_size))</span><br><span class="line"></span><br><span class="line">        gen = Generator(Batch_size, train_lines, inputs_size, num_classes).generate()</span><br><span class="line">        gen_val = Generator(Batch_size, val_lines, inputs_size, num_classes).generate(False)</span><br><span class="line"></span><br><span class="line">        model.fit_generator(gen,</span><br><span class="line">                steps_per_epoch=max(1, len(train_lines)//Batch_size),</span><br><span class="line">                validation_data=gen_val,</span><br><span class="line">                validation_steps=max(1, len(val_lines)//Batch_size),</span><br><span class="line">                epochs=Freeze_Epoch,</span><br><span class="line">                initial_epoch=Init_Epoch,</span><br><span class="line">                callbacks=[checkpoint_period, reduce_lr,tensorboard])</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    for i in range(freeze_layers): model.layers[i].trainable = True</span><br><span class="line"></span><br><span class="line">    if True:</span><br><span class="line">        lr = 1e-5</span><br><span class="line">        Freeze_Epoch = 50</span><br><span class="line">        Unfreeze_Epoch = 100</span><br><span class="line">        Batch_size = 2</span><br><span class="line"></span><br><span class="line">        model.compile(loss = dice_loss_with_CE() if dice_loss else CE(),</span><br><span class="line">                optimizer = Adam(lr=lr),</span><br><span class="line">                metrics = [f_score()])</span><br><span class="line">        print(&#x27;Train on &#123;&#125; samples, val on &#123;&#125; samples, with batch size &#123;&#125;.&#x27;.format(len(train_lines), len(val_lines), Batch_size))</span><br><span class="line"></span><br><span class="line">        gen = Generator(Batch_size, train_lines, inputs_size, num_classes).generate()</span><br><span class="line">        gen_val = Generator(Batch_size, val_lines, inputs_size, num_classes).generate(False)</span><br><span class="line">        </span><br><span class="line">        model.fit_generator(gen,</span><br><span class="line">                steps_per_epoch=max(1, len(train_lines)//Batch_size),</span><br><span class="line">                validation_data=gen_val,</span><br><span class="line">                validation_steps=max(1, len(val_lines)//Batch_size),</span><br><span class="line">                epochs=Unfreeze_Epoch,</span><br><span class="line">                initial_epoch=Freeze_Epoch,</span><br><span class="line">                callbacks=[checkpoint_period, reduce_lr,tensorboard])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="图片预测"><a href="#图片预测" class="headerlink" title="图片预测"></a>图片预测</h1><p>在unet.py中更改三处，1.model_path设置为想要的模型路径。2.num_classes设置为 类别数+1</p>
<p>3.def generate(self):函数的路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line">import colorsys</span><br><span class="line">import copy</span><br><span class="line">import os</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line">from PIL import Image</span><br><span class="line"></span><br><span class="line">from nets.unet import Unet as unet</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#--------------------------------------------#</span><br><span class="line">#   使用自己训练好的模型预测需要修改2个参数</span><br><span class="line">#   model_path和num_classes都需要修改！</span><br><span class="line">#   如果出现shape不匹配</span><br><span class="line">#   一定要注意训练时的model_path和num_classes数的修改</span><br><span class="line">#--------------------------------------------#</span><br><span class="line">class Unet(object):</span><br><span class="line">    _defaults = &#123;</span><br><span class="line">        &quot;model_path&quot;        : &#x27;1.h5&#x27;,</span><br><span class="line">        &quot;model_image_size&quot;  : (512, 512, 3),</span><br><span class="line">        &quot;num_classes&quot;       : 2,</span><br><span class="line">        #--------------------------------#</span><br><span class="line">        #   blend参数用于控制是否</span><br><span class="line">        #   让识别结果和原图混合</span><br><span class="line">        #--------------------------------#</span><br><span class="line">        &quot;blend&quot;             : True,</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    #---------------------------------------------------#</span><br><span class="line">    #   初始化UNET</span><br><span class="line">    #---------------------------------------------------#</span><br><span class="line">    def __init__(self, **kwargs):</span><br><span class="line">        self.__dict__.update(self._defaults)</span><br><span class="line">        self.generate()</span><br><span class="line"></span><br><span class="line">    #---------------------------------------------------#</span><br><span class="line">    #   载入模型</span><br><span class="line">    #---------------------------------------------------#</span><br><span class="line">    def generate(self):</span><br><span class="line">        #-------------------------------#</span><br><span class="line">        #   载入模型与权值</span><br><span class="line">        #-------------------------------#</span><br><span class="line">        self.model = unet(self.model_image_size, self.num_classes)</span><br><span class="line"></span><br><span class="line">        self.model.load_weights(self.model_path)</span><br><span class="line">        print(&#x27;&#123;&#125; model loaded.&#x27;.format(self.model_path))</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        if self.num_classes == 2:</span><br><span class="line">            self.colors = [(255, 255, 255),  (0, 0, 0)]</span><br><span class="line">        elif self.num_classes &lt;= 21:</span><br><span class="line">            self.colors = [(0, 0, 0), (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128), (0, 128, 128), </span><br><span class="line">                    (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0), (192, 128, 0), (64, 0, 128), (192, 0, 128), </span><br><span class="line">                    (64, 128, 128), (192, 128, 128), (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128), (128, 64, 12)]</span><br><span class="line">        else:</span><br><span class="line">            # 画框设置不同的颜色</span><br><span class="line">            hsv_tuples = [(x / len(self.class_names), 1., 1.)</span><br><span class="line">                        for x in range(len(self.class_names))]</span><br><span class="line">            self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))</span><br><span class="line">            self.colors = list(</span><br><span class="line">                map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),</span><br><span class="line">                    self.colors))</span><br><span class="line"></span><br><span class="line">    def letterbox_image(self ,image, size):</span><br><span class="line">        image = image.convert(&quot;RGB&quot;)</span><br><span class="line">        iw, ih = image.size</span><br><span class="line">        w, h = size</span><br><span class="line">        scale = min(w/iw, h/ih)</span><br><span class="line">        nw = int(iw*scale)</span><br><span class="line">        nh = int(ih*scale)</span><br><span class="line"></span><br><span class="line">        image = image.resize((nw,nh), Image.BICUBIC)</span><br><span class="line">        new_image = Image.new(&#x27;RGB&#x27;, size, (128,128,128))</span><br><span class="line">        new_image.paste(image, ((w-nw)//2, (h-nh)//2))</span><br><span class="line">        return new_image,nw,nh</span><br><span class="line"></span><br><span class="line">    #---------------------------------------------------#</span><br><span class="line">    #   检测图片</span><br><span class="line">    #---------------------------------------------------#</span><br><span class="line">    def detect_image(self, image):</span><br><span class="line">        #---------------------------------------------------#</span><br><span class="line">        #   对输入图像进行一个备份，后面用于绘图</span><br><span class="line">        #---------------------------------------------------#</span><br><span class="line">        old_img = copy.deepcopy(image)</span><br><span class="line">        orininal_h = np.array(image).shape[0]</span><br><span class="line">        orininal_w = np.array(image).shape[1]</span><br><span class="line"></span><br><span class="line">        #---------------------------------------------------#</span><br><span class="line">        #   进行不失真的resize，添加灰条，进行图像归一化</span><br><span class="line">        #---------------------------------------------------#</span><br><span class="line">        img, nw, nh = self.letterbox_image(image,(self.model_image_size[1],self.model_image_size[0]))</span><br><span class="line">        img = np.asarray([np.array(img)/255])</span><br><span class="line">        </span><br><span class="line">        #---------------------------------------------------#</span><br><span class="line">        #   图片传入网络进行预测</span><br><span class="line">        #---------------------------------------------------#</span><br><span class="line">        pr = self.model.predict(img)[0]</span><br><span class="line">        #---------------------------------------------------#</span><br><span class="line">        #   取出每一个像素点的种类</span><br><span class="line">        #---------------------------------------------------#</span><br><span class="line">        pr = pr.argmax(axis=-1).reshape([self.model_image_size[0],self.model_image_size[1]])</span><br><span class="line">        #--------------------------------------#</span><br><span class="line">        #   将灰条部分截取掉</span><br><span class="line">        #--------------------------------------#</span><br><span class="line">        pr = pr[int((self.model_image_size[0]-nh)//2):int((self.model_image_size[0]-nh)//2+nh), int((self.model_image_size[1]-nw)//2):int((self.model_image_size[1]-nw)//2+nw)]</span><br><span class="line"></span><br><span class="line">        #------------------------------------------------#</span><br><span class="line">        #   创建一副新图，并根据每个像素点的种类赋予颜色</span><br><span class="line">        #------------------------------------------------#</span><br><span class="line">        seg_img = np.zeros((np.shape(pr)[0],np.shape(pr)[1],3))</span><br><span class="line">        for c in range(self.num_classes):</span><br><span class="line">            seg_img[:,:,0] += ((pr[:,: ] == c )*( self.colors[c][0] )).astype(&#x27;uint8&#x27;)</span><br><span class="line">            seg_img[:,:,1] += ((pr[:,: ] == c )*( self.colors[c][1] )).astype(&#x27;uint8&#x27;)</span><br><span class="line">            seg_img[:,:,2] += ((pr[:,: ] == c )*( self.colors[c][2] )).astype(&#x27;uint8&#x27;)</span><br><span class="line"></span><br><span class="line">        #------------------------------------------------#</span><br><span class="line">        #   将新图片转换成Image的形式</span><br><span class="line">        #------------------------------------------------#</span><br><span class="line">        image = Image.fromarray(np.uint8(seg_img)).resize((orininal_w,orininal_h), Image.NEAREST)</span><br><span class="line"></span><br><span class="line">        #------------------------------------------------#</span><br><span class="line">        #   将新图片和原图片混合</span><br><span class="line">        #------------------------------------------------#</span><br><span class="line">        if self.blend:</span><br><span class="line">            image = Image.blend(old_img,image,0.7)</span><br><span class="line"></span><br><span class="line">        return image</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>运行predict.py</p>
<p><strong>注意：</strong>如果报错AttributeError: ‘str’ object has no attribute ‘decode’</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install h5py==2.10 -i https://pypi.doubanio.com/simple</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/05/GAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="unique_Hang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="unique_Hang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/05/GAN/" class="post-title-link" itemprop="url">GAN</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-05 14:48:34" itemprop="dateCreated datePublished" datetime="2022-04-05T14:48:34+08:00">2022-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-06 14:24:02" itemprop="dateModified" datetime="2022-04-06T14:24:02+08:00">2022-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <meta name="referrer" content="no-referrer" /> 

<p>Welcome to unique_Hang’s blog.</p>
<blockquote>
<p><strong>鲁迅说过：看unique_Hang博客的人颜值都很高！</strong><br> 作者邮箱：<a href="mailto:unique_hang@qq.com">unique_hang@qq.com</a><br>喜欢的小伙伴可以关注我的<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">b站账号</a>(<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">https://space.bilibili.com/290100464</a>)  </p>
</blockquote>
<h1 id="所需python文件"><a href="#所需python文件" class="headerlink" title="所需python文件"></a>所需python文件</h1><h2 id="dataset-py"><a href="#dataset-py" class="headerlink" title="dataset.py"></a>dataset.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_anime_dataset</span>(<span class="params">img_paths, batch_size, resize=<span class="number">64</span>, drop_remainder=<span class="literal">True</span>, shuffle=<span class="literal">True</span>, repeat=<span class="number">1</span></span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># @tf.function</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_map_fn</span>(<span class="params">img</span>):</span><br><span class="line">        img = tf.image.resize(img, [resize, resize])</span><br><span class="line">        <span class="comment"># img = tf.image.random_crop(img,[resize, resize])</span></span><br><span class="line">        <span class="comment"># img = tf.image.random_flip_left_right(img)</span></span><br><span class="line">        <span class="comment"># img = tf.image.random_flip_up_down(img)</span></span><br><span class="line">        img = tf.clip_by_value(img, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">        img = img / <span class="number">127.5</span> - <span class="number">1</span> <span class="comment">#-1~1</span></span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    dataset = disk_image_batch_dataset(img_paths,</span><br><span class="line">                                          batch_size,</span><br><span class="line">                                          drop_remainder=drop_remainder,</span><br><span class="line">                                          map_fn=_map_fn,</span><br><span class="line">                                          shuffle=shuffle,</span><br><span class="line">                                          repeat=repeat)</span><br><span class="line">    img_shape = (resize, resize, <span class="number">3</span>)</span><br><span class="line">    len_dataset = <span class="built_in">len</span>(img_paths) // batch_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset, img_shape, len_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batch_dataset</span>(<span class="params">dataset,</span></span><br><span class="line"><span class="params">                  batch_size,</span></span><br><span class="line"><span class="params">                  drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                  filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                  shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># set defaults</span></span><br><span class="line">    <span class="keyword">if</span> n_map_threads <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        n_map_threads = multiprocessing.cpu_count()</span><br><span class="line">    <span class="keyword">if</span> shuffle <span class="keyword">and</span> shuffle_buffer_size <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        shuffle_buffer_size = <span class="built_in">max</span>(batch_size * <span class="number">128</span>, <span class="number">2048</span>)  <span class="comment"># set the minimum buffer size as 2048</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly</span></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        dataset = dataset.shuffle(shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filter_after_map:</span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># [*] this is slower</span></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">memory_data_batch_dataset</span>(<span class="params">memory_data,</span></span><br><span class="line"><span class="params">                              batch_size,</span></span><br><span class="line"><span class="params">                              drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                              n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                              filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                              shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                              shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of memory data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    memory_data : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices(memory_data)</span><br><span class="line">    dataset = batch_dataset(dataset,</span><br><span class="line">                            batch_size,</span><br><span class="line">                            drop_remainder=drop_remainder,</span><br><span class="line">                            n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                            filter_fn=filter_fn,</span><br><span class="line">                            map_fn=map_fn,</span><br><span class="line">                            n_map_threads=n_map_threads,</span><br><span class="line">                            filter_after_map=filter_after_map,</span><br><span class="line">                            shuffle=shuffle,</span><br><span class="line">                            shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                            repeat=repeat)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">disk_image_batch_dataset</span>(<span class="params">img_paths,</span></span><br><span class="line"><span class="params">                             batch_size,</span></span><br><span class="line"><span class="params">                             labels=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                             n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                             filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                             shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                             shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of disk image for PNG and JPEG.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">        img_paths : 1d-tensor/ndarray/list of str</span></span><br><span class="line"><span class="string">        labels : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        memory_data = img_paths</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        memory_data = (img_paths, labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_fn</span>(<span class="params">path, *label</span>):</span><br><span class="line">        img = tf.io.read_file(path)</span><br><span class="line">        img = tf.image.decode_jpeg(img, channels=<span class="number">3</span>)  <span class="comment"># fix channels to 3</span></span><br><span class="line">        <span class="keyword">return</span> (img,) + label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> map_fn:  <span class="comment"># fuse `map_fn` and `parse_fn`</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">map_fn_</span>(<span class="params">*args</span>):</span><br><span class="line">            <span class="keyword">return</span> map_fn(*parse_fn(*args))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        map_fn_ = parse_fn</span><br><span class="line"></span><br><span class="line">    dataset = memory_data_batch_dataset(memory_data,</span><br><span class="line">                                        batch_size,</span><br><span class="line">                                        drop_remainder=drop_remainder,</span><br><span class="line">                                        n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                                        filter_fn=filter_fn,</span><br><span class="line">                                        map_fn=map_fn_,</span><br><span class="line">                                        n_map_threads=n_map_threads,</span><br><span class="line">                                        filter_after_map=filter_after_map,</span><br><span class="line">                                        shuffle=shuffle,</span><br><span class="line">                                        shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                                        repeat=repeat)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="gan-py"><a href="#gan-py" class="headerlink" title="gan.py"></a>gan.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span>    tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(keras.Model):</span><br><span class="line">    <span class="comment"># 生成器网络</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        <span class="built_in">filter</span> = <span class="number">64</span></span><br><span class="line">        <span class="comment"># 转置卷积层1,输出channel为filter*8,核大小4,步长1,不使用padding,不使用偏置</span></span><br><span class="line">        self.conv1 = layers.Conv2DTranspose(<span class="built_in">filter</span>*<span class="number">8</span>, <span class="number">4</span>,<span class="number">1</span>, <span class="string">&#x27;valid&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = layers.BatchNormalization()</span><br><span class="line">        <span class="comment"># 转置卷积层2</span></span><br><span class="line">        self.conv2 = layers.Conv2DTranspose(<span class="built_in">filter</span>*<span class="number">4</span>, <span class="number">4</span>,<span class="number">2</span>, <span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = layers.BatchNormalization()</span><br><span class="line">        <span class="comment"># 转置卷积层3</span></span><br><span class="line">        self.conv3 = layers.Conv2DTranspose(<span class="built_in">filter</span>*<span class="number">2</span>, <span class="number">4</span>,<span class="number">2</span>, <span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn3 = layers.BatchNormalization()</span><br><span class="line">        <span class="comment"># 转置卷积层4</span></span><br><span class="line">        self.conv4 = layers.Conv2DTranspose(<span class="built_in">filter</span>*<span class="number">1</span>, <span class="number">4</span>,<span class="number">2</span>, <span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn4 = layers.BatchNormalization()</span><br><span class="line">        <span class="comment"># 转置卷积层5</span></span><br><span class="line">        self.conv5 = layers.Conv2DTranspose(<span class="number">3</span>, <span class="number">4</span>,<span class="number">2</span>, <span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span><br><span class="line">        x = inputs <span class="comment"># [z, 100]</span></span><br><span class="line">        <span class="comment"># Reshape乘4D张量，方便后续转置卷积运算:(b, 1, 1, 100)</span></span><br><span class="line">        x = tf.reshape(x, (x.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>, x.shape[<span class="number">1</span>]))</span><br><span class="line">        x = tf.nn.relu(x) <span class="comment"># 激活函数</span></span><br><span class="line">        <span class="comment"># 转置卷积-BN-激活函数:(b, 4, 4, 512)</span></span><br><span class="line">        x = tf.nn.relu(self.bn1(self.conv1(x), training=training))</span><br><span class="line">        <span class="comment"># 转置卷积-BN-激活函数:(b, 8, 8, 256)</span></span><br><span class="line">        x = tf.nn.relu(self.bn2(self.conv2(x), training=training))</span><br><span class="line">        <span class="comment"># 转置卷积-BN-激活函数:(b, 16, 16, 128)</span></span><br><span class="line">        x = tf.nn.relu(self.bn3(self.conv3(x), training=training))</span><br><span class="line">        <span class="comment"># 转置卷积-BN-激活函数:(b, 32, 32, 64)</span></span><br><span class="line">        x = tf.nn.relu(self.bn4(self.conv4(x), training=training))</span><br><span class="line">        <span class="comment"># 转置卷积-激活函数:(b, 64, 64, 3)</span></span><br><span class="line">        x = self.conv5(x)</span><br><span class="line">        x = tf.tanh(x) <span class="comment"># 输出x范围-1~1,与预处理一致</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Discriminator</span>(keras.Model):</span><br><span class="line">    <span class="comment"># 判别器</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Discriminator, self).__init__()</span><br><span class="line">        <span class="built_in">filter</span> = <span class="number">64</span></span><br><span class="line">        <span class="comment"># 卷积层</span></span><br><span class="line">        self.conv1 = layers.Conv2D(<span class="built_in">filter</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="string">&#x27;valid&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = layers.BatchNormalization()</span><br><span class="line">        <span class="comment"># 卷积层</span></span><br><span class="line">        self.conv2 = layers.Conv2D(<span class="built_in">filter</span>*<span class="number">2</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="string">&#x27;valid&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2 = layers.BatchNormalization()</span><br><span class="line">        <span class="comment"># 卷积层</span></span><br><span class="line">        self.conv3 = layers.Conv2D(<span class="built_in">filter</span>*<span class="number">4</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="string">&#x27;valid&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn3 = layers.BatchNormalization()</span><br><span class="line">        <span class="comment"># 卷积层</span></span><br><span class="line">        self.conv4 = layers.Conv2D(<span class="built_in">filter</span>*<span class="number">8</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="string">&#x27;valid&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn4 = layers.BatchNormalization()</span><br><span class="line">        <span class="comment"># 卷积层</span></span><br><span class="line">        self.conv5 = layers.Conv2D(<span class="built_in">filter</span>*<span class="number">16</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="string">&#x27;valid&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn5 = layers.BatchNormalization()</span><br><span class="line">        <span class="comment"># 全局池化层</span></span><br><span class="line">        self.pool = layers.GlobalAveragePooling2D()</span><br><span class="line">        <span class="comment"># 特征打平</span></span><br><span class="line">        self.flatten = layers.Flatten()</span><br><span class="line">        <span class="comment"># 2分类全连接层</span></span><br><span class="line">        self.fc = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 卷积-BN-激活函数:(4, 31, 31, 64)</span></span><br><span class="line">        x = tf.nn.leaky_relu(self.bn1(self.conv1(inputs), training=training))</span><br><span class="line">        <span class="comment"># 卷积-BN-激活函数:(4, 14, 14, 128)</span></span><br><span class="line">        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))</span><br><span class="line">        <span class="comment"># 卷积-BN-激活函数:(4, 6, 6, 256)</span></span><br><span class="line">        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))</span><br><span class="line">        <span class="comment"># 卷积-BN-激活函数:(4, 4, 4, 512)</span></span><br><span class="line">        x = tf.nn.leaky_relu(self.bn4(self.conv4(x), training=training))</span><br><span class="line">        <span class="comment"># 卷积-BN-激活函数:(4, 2, 2, 1024)</span></span><br><span class="line">        x = tf.nn.leaky_relu(self.bn5(self.conv5(x), training=training))</span><br><span class="line">        <span class="comment"># 卷积-BN-激活函数:(4, 1024)</span></span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        <span class="comment"># 打平</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        <span class="comment"># 输出，[b, 1024] =&gt; [b, 1]</span></span><br><span class="line">        logits = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">    d = Discriminator()</span><br><span class="line">    g = Generator()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    x = tf.random.normal([<span class="number">2</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>])</span><br><span class="line">    z = tf.random.normal([<span class="number">2</span>, <span class="number">100</span>])</span><br><span class="line"></span><br><span class="line">    prob = d(x)</span><br><span class="line">    <span class="built_in">print</span>(prob)</span><br><span class="line">    x_hat = g(z)</span><br><span class="line">    <span class="built_in">print</span>(x_hat.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<h2 id="gan-train-py"><a href="#gan-train-py" class="headerlink" title="gan_train.py"></a>gan_train.py</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span>  os</span><br><span class="line"><span class="keyword">import</span>  numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span>  tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span>    tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span>    scipy.misc <span class="keyword">import</span> toimage</span><br><span class="line"><span class="keyword">import</span>  glob</span><br><span class="line"><span class="keyword">from</span>    gan <span class="keyword">import</span> Generator, Discriminator</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span>    dataset <span class="keyword">import</span> make_anime_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_result</span>(<span class="params">val_out, val_block_size, image_path, color_mode</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">img</span>):</span><br><span class="line">        img = ((img + <span class="number">1.0</span>) * <span class="number">127.5</span>).astype(np.uint8)</span><br><span class="line">        <span class="comment"># img = img.astype(np.uint8)</span></span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    preprocesed = preprocess(val_out)</span><br><span class="line">    final_image = np.array([])</span><br><span class="line">    single_row = np.array([])</span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(val_out.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="comment"># concat image into a row</span></span><br><span class="line">        <span class="keyword">if</span> single_row.size == <span class="number">0</span>:</span><br><span class="line">            single_row = preprocesed[b, :, :, :]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># concat image row to final_image</span></span><br><span class="line">        <span class="keyword">if</span> (b+<span class="number">1</span>) % val_block_size == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">if</span> final_image.size == <span class="number">0</span>:</span><br><span class="line">                final_image = single_row</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                final_image = np.concatenate((final_image, single_row), axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># reset single row</span></span><br><span class="line">            single_row = np.array([])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> final_image.shape[<span class="number">2</span>] == <span class="number">1</span>:</span><br><span class="line">        final_image = np.squeeze(final_image, axis=<span class="number">2</span>)</span><br><span class="line">    toimage(final_image).save(image_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">celoss_ones</span>(<span class="params">logits</span>):</span><br><span class="line">    <span class="comment"># 计算属于与标签为1的交叉熵</span></span><br><span class="line">    y = tf.ones_like(logits)</span><br><span class="line">    loss = keras.losses.binary_crossentropy(y, logits, from_logits=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">celoss_zeros</span>(<span class="params">logits</span>):</span><br><span class="line">    <span class="comment"># 计算属于与便签为0的交叉熵</span></span><br><span class="line">    y = tf.zeros_like(logits)</span><br><span class="line">    loss = keras.losses.binary_crossentropy(y, logits, from_logits=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">d_loss_fn</span>(<span class="params">generator, discriminator, batch_z, batch_x, is_training</span>):</span><br><span class="line">    <span class="comment"># 计算判别器的误差函数</span></span><br><span class="line">    <span class="comment"># 采样生成图片</span></span><br><span class="line">    fake_image = generator(batch_z, is_training)</span><br><span class="line">    <span class="comment"># 判定生成图片</span></span><br><span class="line">    d_fake_logits = discriminator(fake_image, is_training)</span><br><span class="line">    <span class="comment"># 判定真实图片</span></span><br><span class="line">    d_real_logits = discriminator(batch_x, is_training)</span><br><span class="line">    <span class="comment"># 真实图片与1之间的误差</span></span><br><span class="line">    d_loss_real = celoss_ones(d_real_logits)</span><br><span class="line">    <span class="comment"># 生成图片与0之间的误差</span></span><br><span class="line">    d_loss_fake = celoss_zeros(d_fake_logits)</span><br><span class="line">    <span class="comment"># 合并误差</span></span><br><span class="line">    loss = d_loss_fake + d_loss_real</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">g_loss_fn</span>(<span class="params">generator, discriminator, batch_z, is_training</span>):</span><br><span class="line">    <span class="comment"># 采样生成图片</span></span><br><span class="line">    fake_image = generator(batch_z, is_training)</span><br><span class="line">    <span class="comment"># 在训练生成网络时，需要迫使生成图片判定为真</span></span><br><span class="line">    d_fake_logits = discriminator(fake_image, is_training)</span><br><span class="line">    <span class="comment"># 计算生成图片与1之间的误差</span></span><br><span class="line">    loss = celoss_ones(d_fake_logits)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">    tf.random.set_seed(<span class="number">3333</span>)</span><br><span class="line">    np.random.seed(<span class="number">3333</span>)</span><br><span class="line">    os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> tf.__version__.startswith(<span class="string">&#x27;2.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    z_dim = <span class="number">100</span> <span class="comment"># 隐藏向量z的长度</span></span><br><span class="line">    epochs = <span class="number">3000000</span> <span class="comment"># 训练步数</span></span><br><span class="line">    batch_size = <span class="number">64</span> <span class="comment"># batch size</span></span><br><span class="line">    learning_rate = <span class="number">0.0002</span></span><br><span class="line">    is_training = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取数据集路径</span></span><br><span class="line">    <span class="comment"># C:\Users\z390\Downloads\anime-faces</span></span><br><span class="line">    <span class="comment"># r&#x27;C:\Users\z390\Downloads\faces\*.jpg&#x27;</span></span><br><span class="line">    img_path = glob.glob(<span class="string">r&#x27;E:\PyCharm\work\15.GAN\dataset\*.jpg&#x27;</span>)</span><br><span class="line">    <span class="comment"># img_path = glob.glob(r&#x27;C:\Users\z390\Downloads\getchu_aligned_with_label\GetChu_aligned2\*.jpg&#x27;)</span></span><br><span class="line">    <span class="comment"># img_path.extend(img_path2)</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;images num:&#x27;</span>, <span class="built_in">len</span>(img_path))</span><br><span class="line">    <span class="comment"># 构建数据集对象</span></span><br><span class="line">    dataset, img_shape, _ = make_anime_dataset(img_path, batch_size, resize=<span class="number">64</span>)</span><br><span class="line">    <span class="built_in">print</span>(dataset, img_shape)</span><br><span class="line">    sample = <span class="built_in">next</span>(<span class="built_in">iter</span>(dataset)) <span class="comment"># 采样</span></span><br><span class="line">    <span class="built_in">print</span>(sample.shape, tf.reduce_max(sample).numpy(),</span><br><span class="line">          tf.reduce_min(sample).numpy())</span><br><span class="line">    dataset = dataset.repeat(<span class="number">100</span>) <span class="comment"># 重复循环</span></span><br><span class="line">    db_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    generator = Generator() <span class="comment"># 创建生成器</span></span><br><span class="line">    generator.build(input_shape = (<span class="number">4</span>, z_dim))</span><br><span class="line">    discriminator = Discriminator() <span class="comment"># 创建判别器</span></span><br><span class="line">    discriminator.build(input_shape=(<span class="number">4</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>))</span><br><span class="line">    <span class="comment"># 分别为生成器和判别器创建优化器</span></span><br><span class="line">    g_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=<span class="number">0.5</span>)</span><br><span class="line">    d_optimizer = keras.optimizers.Adam(learning_rate=learning_rate, beta_1=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#断点续训</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(<span class="string">&#x27;generator.ckpt&#x27;</span>+<span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">        generator.load_weights(<span class="string">&#x27;generator.ckpt&#x27;</span>)</span><br><span class="line">        discriminator.load_weights(<span class="string">&#x27;discriminator.ckpt&#x27;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Loaded chpt!!&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    d_losses, g_losses = [],[]</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs): <span class="comment"># 训练epochs次</span></span><br><span class="line">        <span class="comment"># 1. 训练判别器</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>):</span><br><span class="line">            <span class="comment"># 采样隐藏向量</span></span><br><span class="line">            batch_z = tf.random.normal([batch_size, z_dim])</span><br><span class="line">            batch_x = <span class="built_in">next</span>(db_iter) <span class="comment"># 采样真实图片</span></span><br><span class="line">            <span class="comment"># 判别器前向计算</span></span><br><span class="line">            <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">                d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)</span><br><span class="line">            grads = tape.gradient(d_loss, discriminator.trainable_variables)</span><br><span class="line">            d_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, discriminator.trainable_variables))</span><br><span class="line">        <span class="comment"># 2. 训练生成器</span></span><br><span class="line">        <span class="comment"># 采样隐藏向量</span></span><br><span class="line">        batch_z = tf.random.normal([batch_size, z_dim])</span><br><span class="line">        batch_x = <span class="built_in">next</span>(db_iter) <span class="comment"># 采样真实图片</span></span><br><span class="line">        <span class="comment"># 生成器前向计算</span></span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)</span><br><span class="line">        grads = tape.gradient(g_loss, generator.trainable_variables)</span><br><span class="line">        g_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, generator.trainable_variables))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(epoch, <span class="string">&#x27;d-loss:&#x27;</span>,<span class="built_in">float</span>(d_loss), <span class="string">&#x27;g-loss:&#x27;</span>, <span class="built_in">float</span>(g_loss))</span><br><span class="line">            <span class="comment"># 可视化</span></span><br><span class="line">            z = tf.random.normal([<span class="number">100</span>, z_dim])</span><br><span class="line">            fake_image = generator(z, training=<span class="literal">False</span>)</span><br><span class="line">            img_path = os.path.join(<span class="string">&#x27;gan_images&#x27;</span>, <span class="string">&#x27;gan-%d.png&#x27;</span>%epoch)</span><br><span class="line">            save_result(fake_image.numpy(), <span class="number">10</span>, img_path, color_mode=<span class="string">&#x27;P&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            d_losses.append(<span class="built_in">float</span>(d_loss))</span><br><span class="line">            g_losses.append(<span class="built_in">float</span>(g_loss))</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> epoch % <span class="number">300</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># print(d_losses)</span></span><br><span class="line">                <span class="comment"># print(g_losses)</span></span><br><span class="line">                generator.save_weights(<span class="string">&#x27;generator.ckpt&#x27;</span>)</span><br><span class="line">                discriminator.save_weights(<span class="string">&#x27;discriminator.ckpt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">            </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>



<h1 id="How-to-use？"><a href="#How-to-use？" class="headerlink" title="How to use？"></a>How to use？</h1><h2 id="打开gan-train-py"><a href="#打开gan-train-py" class="headerlink" title="打开gan_train.py"></a>打开gan_train.py</h2><p>设置数据集路径：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">img_path = glob.glob(<span class="string">r&#x27;E:\PyCharm\work\15.GAN\dataset\*.jpg&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="在当前文件夹中创建文件夹：gan-images"><a href="#在当前文件夹中创建文件夹：gan-images" class="headerlink" title="在当前文件夹中创建文件夹：gan_images"></a>在当前文件夹中创建文件夹：gan_images</h2><p>用于存放输出图片</p>
<p><img src="https://wx4.sinaimg.cn/mw690/007BSstUgy1gnbe5d111rj308205ct8q.jpg"></p>
<h2 id="运行gan-train-py即可在gan-images文件夹看到输出结果"><a href="#运行gan-train-py即可在gan-images文件夹看到输出结果" class="headerlink" title="运行gan_train.py即可在gan_images文件夹看到输出结果"></a>运行gan_train.py即可在gan_images文件夹看到输出结果</h2>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/05/CNN%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA%E5%85%A8%E8%BF%87%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="unique_Hang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="unique_Hang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/05/CNN%E7%BD%91%E7%BB%9C%E6%90%AD%E5%BB%BA%E5%85%A8%E8%BF%87%E7%A8%8B/" class="post-title-link" itemprop="url">CNN网络搭建全过程</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-05 14:47:27" itemprop="dateCreated datePublished" datetime="2022-04-05T14:47:27+08:00">2022-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-06 14:23:33" itemprop="dateModified" datetime="2022-04-06T14:23:33+08:00">2022-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <meta name="referrer" content="no-referrer" /> 

<p>Welcome to unique_Hang’s blog.</p>
<blockquote>
<p><strong>鲁迅说过：看unique_Hang博客的人颜值都很高！</strong><br> 作者邮箱：<a href="mailto:unique_hang@qq.com">unique_hang@qq.com</a><br>喜欢的小伙伴可以关注我的<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">b站账号</a>(<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">https://space.bilibili.com/290100464</a>)  </p>
</blockquote>
<h1 id="论文必备：画图"><a href="#论文必备：画图" class="headerlink" title="论文必备：画图"></a>论文必备：画图</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#画图：https://cbovar.github.io/ConvNetDraw/</span></span><br></pre></td></tr></table></figure>

<p><strong>卷积是什么？</strong></p>
<p><img src="https://wx4.sinaimg.cn/mw1024/007BSstUgy1gn39tqzjb0j30yg0cftl2.jpg"></p>
<h1 id="搭建网络的步骤"><a href="#搭建网络的步骤" class="headerlink" title="搭建网络的步骤"></a>搭建网络的步骤</h1><h2 id="搭建网络class"><a href="#搭建网络class" class="headerlink" title="搭建网络class"></a>搭建网络class</h2><h3 id="1、六步法"><a href="#1、六步法" class="headerlink" title="1、六步法"></a>1、六步法</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1)import——导入所需的各种库和包 </span><br><span class="line">2)x_train, y_train——导入数据集、自制数据集、数据增强 </span><br><span class="line">3)class MyModel(Model) model=MyModel——定义模型 </span><br><span class="line">4)model.compile——配置模型 </span><br><span class="line">5)model.fit——训练模型、断点续训 </span><br><span class="line">6)model.summary——参数提取、acc/loss 可视化、前向推理实现应用 </span><br></pre></td></tr></table></figure>

<h3 id="2、用class类封装神经网络函数"><a href="#2、用class类封装神经网络函数" class="headerlink" title="2、用class类封装神经网络函数"></a>2、用class类封装神经网络函数</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line">        定义网络结构块</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        调用网络结构块，实现前向传播</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"><span class="comment">#实例化出model</span></span><br><span class="line">model=MyModel()</span><br></pre></td></tr></table></figure>

<p>init()函数准备搭建网络所需的“积木”</p>
<p>call()函数调用init()中搭好的积木</p>
<h3 id="3、示例"><a href="#3、示例" class="headerlink" title="3、示例"></a>3、示例</h3><p>用class为鸢尾花分类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IrisModel</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(IrisModel, self).__init__()</span><br><span class="line">        self.d1 = Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        y = self.d1(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = IrisModel()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">500</span>, validation_split=<span class="number">0.2</span>, validation_freq=<span class="number">20</span>)</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="搭建网络sequential"><a href="#搭建网络sequential" class="headerlink" title="搭建网络sequential"></a>搭建网络sequential</h2><h3 id="1、六步法-1"><a href="#1、六步法-1" class="headerlink" title="1、六步法"></a>1、六步法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>)<span class="keyword">import</span>——导入所需的各种库和包 </span><br><span class="line"><span class="number">2</span>)x_train, y_train——导入数据集、自制数据集、数据增强 </span><br><span class="line"><span class="number">3</span>)model=tf.keras.models.Sequential  </span><br><span class="line"><span class="number">4</span>)model.<span class="built_in">compile</span>——配置模型 </span><br><span class="line"><span class="number">5</span>)model.fit——训练模型、断点续训 </span><br><span class="line"><span class="number">6</span>)model.summary——参数提取、acc/loss 可视化、前向推理实现应用 </span><br></pre></td></tr></table></figure>

<h3 id="2、compile-配置神经网络的训练方法"><a href="#2、compile-配置神经网络的训练方法" class="headerlink" title="2、compile()配置神经网络的训练方法"></a>2、compile()配置神经网络的训练方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;优化器&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;损失函数&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;准确率&#x27;</span>]</span><br><span class="line">              )</span><br></pre></td></tr></table></figure>

<h4 id="Optimizer可选："><a href="#Optimizer可选：" class="headerlink" title="Optimizer可选："></a>Optimizer可选：</h4><p>“<strong>sgd</strong>”  或者  tf.optimizers.SGD(lr &#x3D; 学习率，decay &#x3D; 学习率衰减率，momentum &#x3D; 动量参数）</p>
<p> “<strong>adagrad</strong>“ 或者 tf.keras.optimizers.Adagrad(lr &#x3D; 学习率，decay &#x3D; 学习率衰减率）</p>
<p> ”<strong>adadelta</strong>“ 或者 tf.keras.optimizers.Adadelta(lr &#x3D; 学习率， decay &#x3D; 学习率衰减率）</p>
<p>“<strong>adam</strong>“ 或者 tf.keras.optimizers.Adam(lr &#x3D; 学习率，decay &#x3D; 学习率衰减率）</p>
<h4 id="loss可选："><a href="#loss可选：" class="headerlink" title="loss可选："></a>loss可选：</h4><p>”<strong>mse</strong>“ 或者 tf.keras.losses.MeanSquaredError()</p>
<p>“<strong>sparse_categorical_crossentropy</strong>“ 或者 tf.keras.losses.SparseCatagoricalCrossentropy(from_logits &#x3D; False)</p>
<p><u><em><strong>注：损失函数经常需要使用softmax函数来将输出转化为概率分布的形式，在这里from_logits代表是否将输出转为概率分布的形式，为False时表示转换为概率分布，为True时表示不转换，直接输出（即：网络用了’softmax‘则from_logits &#x3D; False，反之使用True）</strong></em>。</u></p>
<h4 id="metrics可选："><a href="#metrics可选：" class="headerlink" title="metrics可选："></a>metrics可选：</h4><p>“<strong>accuracy</strong>“ : y_ 和 y 都是数值，如y_ &#x3D; [1] y &#x3D; [1] #y_为真实值，y为预测值</p>
<p>“<strong>sparse_accuracy</strong>“:y_ 和y都是以独热码 和概率分布表示，如y_ &#x3D; [0, 1, 0], y &#x3D; [0.256, 0.695, 0.048]</p>
<p> “<strong>sparse_categorical_accuracy</strong>“ :y_ 是以数值形式给出，y是以独热码给出，如y_ &#x3D; [1], y &#x3D; [0.256 0.695, 0.048]</p>
<p><u><em><strong>注：使用了’softmax’，输出会变成独热码形式</strong></em></u></p>
<h3 id="3、fit-执行训练过程"><a href="#3、fit-执行训练过程" class="headerlink" title="3、fit()执行训练过程"></a>3、fit()执行训练过程</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.fit(训练集输入,训练集标签,batch_size= , epochs= ,</span><br><span class="line">                    validation_data=(测试集输入,测试集标签),</span><br><span class="line">                    validation_split=从训练集划分多少比例给测试集,</span><br><span class="line">                    validation_freq=1)</span><br></pre></td></tr></table></figure>

<h3 id="4、tf描述卷积层"><a href="#4、tf描述卷积层" class="headerlink" title="4、tf描述卷积层"></a>4、tf描述卷积层</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">keras.layers.Conv2D(filters=卷积核个数,kernel_size=卷积核尺寸,strides=滑动步长（默认为<span class="number">1</span>）,padding=<span class="string">&#x27;same&#x27;</span> <span class="keyword">or</span> <span class="string">&#x27;valid&#x27;</span>,activation=<span class="string">&#x27;relu&#x27;</span> <span class="keyword">or</span> <span class="string">&#x27;sigmoid&#x27;</span> <span class="keyword">or</span> <span class="string">&#x27;tanh&#x27;</span> <span class="keyword">or</span> <span class="string">&#x27;softmax&#x27;</span>,input_shape=(高,宽,通道数))</span><br></pre></td></tr></table></figure>

<p><strong><u>注意：如果卷积后面有批标准化操作（keras.layers.BatchNormalization），这里不用激活，不写激活函数。</u></strong></p>
<p><img src="https://wx4.sinaimg.cn/mw1024/007BSstUgy1gn2kspj8xlj31720r84qp.jpg"></p>
<h1 id="缓解过拟合的方法"><a href="#缓解过拟合的方法" class="headerlink" title="缓解过拟合的方法"></a>缓解过拟合的方法</h1><h2 id="1、正则化"><a href="#1、正则化" class="headerlink" title="1、正则化"></a>1、正则化</h2><p>（1)L1正则化大概率会使很多参数变为零，因此该方法可<strong>通过稀疏参数，即减少参数的数量，降低复杂度。</strong></p>
<p>（2)L2正则化会使参数很接近零但不为零，因此该方法可<strong>通过减小参数值的大小降低复杂度。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = keras.models.Sequential()</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">256</span>,kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>),activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">64</span>,kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>),activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">5</span>,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h2 id="2、动量"><a href="#2、动量" class="headerlink" title="2、动量"></a>2、动量</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">optimizer=SGD(learning_rate=<span class="number">0.02</span>,momentum=<span class="number">0.9</span>)</span><br><span class="line">optimizer=RMSprop(learning_rate=<span class="number">0.02</span>,momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">optimizer=Adam(learning_rate=<span class="number">0.02</span>,</span><br><span class="line">              beta_1=<span class="number">0.9</span>,</span><br><span class="line">              beta_2=<span class="number">0.999</span>)</span><br></pre></td></tr></table></figure>

<h2 id="3、学习率"><a href="#3、学习率" class="headerlink" title="3、学习率"></a>3、学习率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">optimizer=SGD(learning_rate=<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    optimizer.learning_rate=<span class="number">0.2</span>*(<span class="number">100</span>-epoch)/<span class="number">100</span></span><br></pre></td></tr></table></figure>

<h2 id="4、Dropout"><a href="#4、Dropout" class="headerlink" title="4、Dropout"></a>4、Dropout</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = keras.models.Sequential()</span><br><span class="line"></span><br><span class="line">model.add(keras.layers.Dense(<span class="number">256</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">64</span>,activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.2</span>))</span><br><span class="line">model.add(keras.layers.Dense(<span class="number">5</span>,activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h2 id="5、BatchNormalization"><a href="#5、BatchNormalization" class="headerlink" title="5、BatchNormalization"></a>5、BatchNormalization</h2><p>通常加在卷积层与激活层之间</p>
<p><img src="https://wx2.sinaimg.cn/mw1024/007BSstUgy1gn39e1vfi6j30yr09r46v.jpg"></p>
<h2 id="6、池化"><a href="#6、池化" class="headerlink" title="6、池化"></a>6、池化</h2><p>1）最大池化可以提取图片纹理</p>
<p>2）均值池化可以保留背景特征</p>
<h1 id="进阶操作"><a href="#进阶操作" class="headerlink" title="进阶操作"></a>进阶操作</h1><h2 id="1、自制数据集"><a href="#1、自制数据集" class="headerlink" title="1、自制数据集"></a>1、自制数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">train_path = <span class="string">&#x27;./mnist_image_label/mnist_train_jpg_60000/&#x27;</span></span><br><span class="line">train_txt = <span class="string">&#x27;./mnist_image_label/mnist_train_jpg_60000.txt&#x27;</span></span><br><span class="line">x_train_savepath = <span class="string">&#x27;./mnist_image_label/mnist_x_train.npy&#x27;</span></span><br><span class="line">y_train_savepath = <span class="string">&#x27;./mnist_image_label/mnist_y_train.npy&#x27;</span></span><br><span class="line"></span><br><span class="line">test_path = <span class="string">&#x27;./mnist_image_label/mnist_test_jpg_10000/&#x27;</span></span><br><span class="line">test_txt = <span class="string">&#x27;./mnist_image_label/mnist_test_jpg_10000.txt&#x27;</span></span><br><span class="line">x_test_savepath = <span class="string">&#x27;./mnist_image_label/mnist_x_test.npy&#x27;</span></span><br><span class="line">y_test_savepath = <span class="string">&#x27;./mnist_image_label/mnist_y_test.npy&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generateds</span>(<span class="params">path, txt</span>):</span><br><span class="line">    f = <span class="built_in">open</span>(txt, <span class="string">&#x27;r&#x27;</span>)  <span class="comment"># 以只读形式打开txt文件</span></span><br><span class="line">    contents = f.readlines()  <span class="comment"># 读取文件中所有行</span></span><br><span class="line">    f.close()  <span class="comment"># 关闭txt文件</span></span><br><span class="line">    x, y_ = [], []  <span class="comment"># 建立空列表</span></span><br><span class="line">    <span class="keyword">for</span> content <span class="keyword">in</span> contents:  <span class="comment"># 逐行取出</span></span><br><span class="line">        value = content.split()  <span class="comment"># 以空格分开，图片路径为value[0] , 标签为value[1] , 存入列表</span></span><br><span class="line">        img_path = path + value[<span class="number">0</span>]  <span class="comment"># 拼出图片路径和文件名</span></span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_path)  <span class="comment"># 读入图片</span></span><br><span class="line">        img = np.array(img.convert(<span class="string">&#x27;L&#x27;</span>))  <span class="comment"># 图片变为8位宽灰度值的np.array格式</span></span><br><span class="line">        img = img / <span class="number">255.</span>  <span class="comment"># 数据归一化 （实现预处理）</span></span><br><span class="line">        x.append(img)  <span class="comment"># 归一化后的数据，贴到列表x</span></span><br><span class="line">        y_.append(value[<span class="number">1</span>])  <span class="comment"># 标签贴到列表y_</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;loading : &#x27;</span> + content)  <span class="comment"># 打印状态提示</span></span><br><span class="line"></span><br><span class="line">    x = np.array(x)  <span class="comment"># 变为np.array格式</span></span><br><span class="line">    y_ = np.array(y_)  <span class="comment"># 变为np.array格式</span></span><br><span class="line">    y_ = y_.astype(np.int64)  <span class="comment"># 变为64位整型</span></span><br><span class="line">    <span class="keyword">return</span> x, y_  <span class="comment"># 返回输入特征x，返回标签y_</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> os.path.exists(x_train_savepath) <span class="keyword">and</span> os.path.exists(y_train_savepath) <span class="keyword">and</span> os.path.exists(</span><br><span class="line">        x_test_savepath) <span class="keyword">and</span> os.path.exists(y_test_savepath):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------Load Datasets-----------------&#x27;</span>)</span><br><span class="line">    x_train_save = np.load(x_train_savepath)</span><br><span class="line">    y_train = np.load(y_train_savepath)</span><br><span class="line">    x_test_save = np.load(x_test_savepath)</span><br><span class="line">    y_test = np.load(y_test_savepath)</span><br><span class="line">    x_train = np.reshape(x_train_save, (<span class="built_in">len</span>(x_train_save), <span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line">    x_test = np.reshape(x_test_save, (<span class="built_in">len</span>(x_test_save), <span class="number">28</span>, <span class="number">28</span>))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------Generate Datasets-----------------&#x27;</span>)</span><br><span class="line">    x_train, y_train = generateds(train_path, train_txt)</span><br><span class="line">    x_test, y_test = generateds(test_path, test_txt)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------Save Datasets-----------------&#x27;</span>)</span><br><span class="line">    x_train_save = np.reshape(x_train, (<span class="built_in">len</span>(x_train), -<span class="number">1</span>))</span><br><span class="line">    x_test_save = np.reshape(x_test, (<span class="built_in">len</span>(x_test), -<span class="number">1</span>))</span><br><span class="line">    np.save(x_train_savepath, x_train_save)</span><br><span class="line">    np.save(y_train_savepath, y_train)</span><br><span class="line">    np.save(x_test_savepath, x_test_save)</span><br><span class="line">    np.save(y_test_savepath, y_test)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<p>第一遍运行可以制作出npy格式的数据集</p>
<p><img src="https://wx3.sinaimg.cn/mw690/007BSstUgy1gn27y28ievj30rw052abz.jpg"></p>
<p>当已经有了npy格式的数据集运行程序可以直接加载数据集</p>
<p><img src="https://wx1.sinaimg.cn/mw690/007BSstUgy1gn27zvw9jrj309j0190t1.jpg"></p>
<h2 id="2、数据增强（可增加泛化性）"><a href="#2、数据增强（可增加泛化性）" class="headerlink" title="2、数据增强（可增加泛化性）"></a>2、数据增强（可增加泛化性）</h2><p><img src="https://wx4.sinaimg.cn/large/007BSstUgy1gn286mljjfj31430elqh9.jpg"></p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">image_gen_train = tf.keras.preprocessing.image.ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span> / <span class="number">255</span>,	<span class="comment">#归至0~1</span></span><br><span class="line">    rotation_range=<span class="number">45</span>,	<span class="comment">#随机45度旋转</span></span><br><span class="line">    width_shift_range=<span class="number">.15</span>,	<span class="comment">#宽度偏移</span></span><br><span class="line">    height_shift_range=<span class="number">.15</span>,	<span class="comment">#高度偏移</span></span><br><span class="line">    horizontal_flip=<span class="literal">False</span>,	<span class="comment">#水平翻转</span></span><br><span class="line">    zoom_range=<span class="number">0.5</span>	<span class="comment">#将图片随机缩放阈量50%</span></span><br><span class="line">)</span><br><span class="line">image_gen_train.fit(x_train)</span><br></pre></td></tr></table></figure>

<p>因为fit需要输入一个四维数据，需要对x_train进行reshape</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://wx3.sinaimg.cn/mw690/007BSstUgy1gn28djs0k4j30c9011t90.jpg"></p>
<p>最后的1是单通道</p>
<p>完整实例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line">x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)  <span class="comment"># 给数据增加一个维度,从(60000, 28, 28)reshape为(60000, 28, 28, 1)</span></span><br><span class="line"></span><br><span class="line">image_gen_train = ImageDataGenerator(</span><br><span class="line">    rescale=<span class="number">1.</span> / <span class="number">1.</span>,  <span class="comment"># 如为图像，分母为255时，可归至0～1</span></span><br><span class="line">    rotation_range=<span class="number">45</span>,  <span class="comment"># 随机45度旋转</span></span><br><span class="line">    width_shift_range=<span class="number">.15</span>,  <span class="comment"># 宽度偏移</span></span><br><span class="line">    height_shift_range=<span class="number">.15</span>,  <span class="comment"># 高度偏移</span></span><br><span class="line">    horizontal_flip=<span class="literal">False</span>,  <span class="comment"># 水平翻转</span></span><br><span class="line">    zoom_range=<span class="number">0.5</span>  <span class="comment"># 将图像随机缩放阈量50％</span></span><br><span class="line">)</span><br><span class="line">image_gen_train.fit(x_train)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(image_gen_train.flow(x_train, y_train, batch_size=<span class="number">32</span>), epochs=<span class="number">5</span>, validation_data=(x_test, y_test),</span><br><span class="line">          validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<p>重点部分如下：</p>
<p><img src="https://wx2.sinaimg.cn/large/007BSstUgy1gn28n5hotbj31hc0u0azi.jpg"></p>
<h2 id="3、断点续训"><a href="#3、断点续训" class="headerlink" title="3、断点续训"></a>3、断点续训</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/mnist.ckpt&quot;</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line"></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>,callbacks=[cp_callback])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<p>重点为：</p>
<p><img src="https://wx1.sinaimg.cn/large/007BSstUgy1gn29ulti7xj31hc0u0khv.jpg"></p>
<h2 id="4、参数提取"><a href="#4、参数提取" class="headerlink" title="4、参数提取"></a>4、参数提取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.set_printoptions(threshold=np.inf)</span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/mnist.ckpt&quot;</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>)</span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>,</span><br><span class="line">                    callbacks=[cp_callback])</span><br><span class="line">model.summary()</span><br><span class="line"><span class="built_in">print</span>(model.trainable_variables)</span><br><span class="line">file = <span class="built_in">open</span>(<span class="string">&#x27;./weights.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> model.trainable_variables:</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.name) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.shape) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.numpy()) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">file.close()</span><br></pre></td></tr></table></figure>

<p>重点如下：</p>
<p><img src="https://wx3.sinaimg.cn/large/007BSstUgy1gn2a4zxtoyj31hc0u0b12.jpg"></p>
<p>可把网络参数保存至‘weights.txt’中</p>
<h2 id="5、acc-x2F-loss可视化"><a href="#5、acc-x2F-loss可视化" class="headerlink" title="5、acc&#x2F;loss可视化"></a>5、acc&#x2F;loss可视化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">np.set_printoptions(threshold=np.inf)</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/mnist.ckpt&quot;</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line"></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>,</span><br><span class="line">                    callbacks=[cp_callback])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(model.trainable_variables)</span><br><span class="line">file = <span class="built_in">open</span>(<span class="string">&#x27;./weights.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> model.trainable_variables:</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.name) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.shape) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.numpy()) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">###############################################    show   ###############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练集和验证集的acc和loss曲线</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.plot(val_acc, label=<span class="string">&#x27;Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(val_loss, label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>重点如下：</p>
<p><img src="https://wx4.sinaimg.cn/large/007BSstUgy1gn2a9ztyfpj31hc0u01kx.jpg"></p>
<p>效果如下：</p>
<p><img src="https://wx2.sinaimg.cn/mw690/007BSstUgy1gn2ab3t2hij30qm0mogq3.jpg"></p>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, Model, optimizers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io,transform</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span>  <span class="comment"># 忽略低级别警告</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class_num=<span class="number">10</span>    <span class="comment">#分类数</span></span><br><span class="line"></span><br><span class="line">image_path = <span class="string">&#x27;.\\dataset\\dataset&#x27;</span></span><br><span class="line">train_dir = os.path.join(image_path, <span class="string">&quot;train&quot;</span>)</span><br><span class="line">validation_dir = os.path.join(image_path, <span class="string">&quot;val&quot;</span>)</span><br><span class="line"><span class="keyword">assert</span> os.path.exists(train_dir), <span class="string">&quot;cannot find &#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_dir)</span><br><span class="line"><span class="keyword">assert</span> os.path.exists(validation_dir), <span class="string">&quot;cannot find &#123;&#125;&quot;</span>.<span class="built_in">format</span>(validation_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create direction for saving weights</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;if not os.path.exists(&quot;save_weights&quot;):</span></span><br><span class="line"><span class="string">    os.makedirs(&quot;save_weights&quot;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">im_height = <span class="number">64</span></span><br><span class="line">im_width = <span class="number">64</span></span><br><span class="line">batch_size = <span class="number">16</span></span><br><span class="line">epochs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># data generator with data augmentation</span></span><br><span class="line"><span class="comment">#lable is one-hot coding</span></span><br><span class="line">train_image_generator = ImageDataGenerator(rescale=<span class="number">1.</span> / <span class="number">255</span>,</span><br><span class="line">                                           horizontal_flip=<span class="literal">True</span>)</span><br><span class="line">validation_image_generator = ImageDataGenerator(rescale=<span class="number">1.</span> / <span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_data_gen = train_image_generator.flow_from_directory(directory=train_dir,</span><br><span class="line">                                                           batch_size=batch_size,</span><br><span class="line">                                                           shuffle=<span class="literal">True</span>,</span><br><span class="line">                                                           target_size=(im_height, im_width),</span><br><span class="line">                                                           class_mode=<span class="string">&#x27;categorical&#x27;</span>)</span><br><span class="line">total_train = train_data_gen.n</span><br><span class="line"></span><br><span class="line"><span class="comment"># get class dict</span></span><br><span class="line">class_indices = train_data_gen.class_indices</span><br><span class="line"></span><br><span class="line"><span class="comment"># transform value and key of dict</span></span><br><span class="line">inverse_dict = <span class="built_in">dict</span>((val, key) <span class="keyword">for</span> key, val <span class="keyword">in</span> class_indices.items())</span><br><span class="line"><span class="comment"># write dict into json file</span></span><br><span class="line">json_str = json.dumps(inverse_dict, indent=<span class="number">4</span>)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;class_indices.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(json_str)</span><br><span class="line"></span><br><span class="line">val_data_gen = validation_image_generator.flow_from_directory(directory=validation_dir,</span><br><span class="line">                                                              batch_size=batch_size,</span><br><span class="line">                                                              shuffle=<span class="literal">False</span>,</span><br><span class="line">                                                              target_size=(im_height, im_width),</span><br><span class="line">                                                              class_mode=<span class="string">&#x27;categorical&#x27;</span>)</span><br><span class="line">total_val = val_data_gen.n</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="built_in">format</span>(total_train,</span><br><span class="line">                                                                       total_val))</span><br><span class="line"><span class="comment">##############################################</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet8</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(AlexNet8, self).__init__()</span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">        self.b1 = BatchNormalization()</span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.c2 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">        self.b2 = BatchNormalization()</span><br><span class="line">        self.a2 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p2 = MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.c3 = Conv2D(filters=<span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                         activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c4 = Conv2D(filters=<span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                         activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c5 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                         activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p3 = MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">2048</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d1 = Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">2048</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d2 = Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.f3 = Dense(class_num, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.c1(x)</span><br><span class="line">        x = self.b1(x)</span><br><span class="line">        x = self.a1(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line"></span><br><span class="line">        x = self.c2(x)</span><br><span class="line">        x = self.b2(x)</span><br><span class="line">        x = self.a2(x)</span><br><span class="line">        x = self.p2(x)</span><br><span class="line"></span><br><span class="line">        x = self.c3(x)</span><br><span class="line"></span><br><span class="line">        x = self.c4(x)</span><br><span class="line"></span><br><span class="line">        x = self.c5(x)</span><br><span class="line">        x = self.p3(x)</span><br><span class="line"></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.f1(x)</span><br><span class="line">        x = self.d1(x)</span><br><span class="line">        x = self.f2(x)</span><br><span class="line">        x = self.d2(x)</span><br><span class="line">        y = self.f3(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = AlexNet8()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置训练学习过程，设置损失函数，优化器和训练指标</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="number">0.0005</span>),</span><br><span class="line">              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&quot;accuracy&quot;</span>])</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">model.compile(optimizer=&#x27;adam&#x27;,</span></span><br><span class="line"><span class="string">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),</span></span><br><span class="line"><span class="string">              metrics=[&#x27;sparse_categorical_accuracy&#x27;])</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#断点继训</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(<span class="string">&#x27;./logs/models.ckpt&#x27;</span> + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(<span class="string">&#x27;./logs/models.ckpt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">##保存训练过程</span></span><br><span class="line">logdir = os.path.join(<span class="string">&#x27;logs&#x27;</span>)<span class="comment">#win10下的bug，</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(logdir):</span><br><span class="line">    os.makedirs(logdir)</span><br><span class="line">output_model_file = os.path.join(logdir,<span class="string">&#x27;models.ckpt&#x27;</span>)</span><br><span class="line">callbacks = [</span><br><span class="line">    keras.callbacks.TensorBoard(logdir),</span><br><span class="line">    keras.callbacks.ModelCheckpoint(output_model_file, monitor=<span class="string">&#x27;val_loss&#x27;</span>, verbose=<span class="number">0</span>, save_best_only=<span class="literal">True</span>, save_weights_only=<span class="literal">True</span>, mode=<span class="string">&#x27;auto&#x27;</span>, period=<span class="number">1</span>),</span><br><span class="line">    <span class="comment">#keras.callbacks.EarlyStopping(patience=5,min_delta=1e-3)</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">output_model_file: 字符串，保存模型的路径。</span></span><br><span class="line"><span class="string">monitor: 被监测的数据。val_acc或这val_loss</span></span><br><span class="line"><span class="string">verbose: 详细信息模式，0 或者 1 。0为不打印输出信息，1打印</span></span><br><span class="line"><span class="string">save_best_only: 如果 save_best_only=True， 将只保存在验证集上性能最好的模型</span></span><br><span class="line"><span class="string">mode: &#123;auto, min, max&#125; 的其中之一。 如果 save_best_only=True，那么是否覆盖保存文件的决定就取决于被监测数据的最大或者最小值。 对于 val_acc，模式就会是 max，而对于 val_loss，模式就需要是 min，等等。 在 auto 模式中，方向会自动从被监测的数据的名字中判断出来。</span></span><br><span class="line"><span class="string">save_weights_only: 如果 True，那么只有模型的权重会被保存 (model.save_weights(filepath))， 否则的话，整个模型会被保存 (model.save(filepath))。</span></span><br><span class="line"><span class="string">period: 每个检查点之间的间隔（训练轮数）。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">history = model.fit(x=train_data_gen,</span><br><span class="line">                    steps_per_epoch=total_train // batch_size,</span><br><span class="line">                    epochs=epochs,</span><br><span class="line">                    validation_data=val_data_gen,</span><br><span class="line">                    validation_steps=total_val // batch_size,</span><br><span class="line">                    callbacks=callbacks)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">plt.plot(history.history[&#x27;accuracy&#x27;], label=&#x27;accuracy&#x27;)</span></span><br><span class="line"><span class="string">plt.plot(history.history[&#x27;val_accuracy&#x27;], label = &#x27;val_accuracy&#x27;)</span></span><br><span class="line"><span class="string">plt.xlabel(&#x27;Epoch&#x27;)</span></span><br><span class="line"><span class="string">plt.ylabel(&#x27;Accuracy&#x27;)</span></span><br><span class="line"><span class="string">plt.ylim([0.5, 1])</span></span><br><span class="line"><span class="string">plt.legend(loc=&#x27;lower right&#x27;)</span></span><br><span class="line"><span class="string">plt.show()</span></span><br><span class="line"><span class="string"> &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">###############################################    show   ###############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练集和验证集的acc和loss曲线</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;accuracy&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.plot(val_acc, label=<span class="string">&#x27;Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(val_loss, label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">test_loss, test_acc = model.evaluate(val_data_gen, verbose=<span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(test_acc)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型保存</span></span><br><span class="line">save_path = <span class="string">&quot;垃圾分类_model.h5&quot;</span></span><br><span class="line">model.save(save_path)</span><br></pre></td></tr></table></figure>

<p>备注：运行前把脚本和数据集放在一起，把图片分为测试集和验证集，数据集命名为‘photos’如下：</p>
<p><img src="https://wx3.sinaimg.cn/mw690/007BSstUgy1gna4st5x9ij3057025t8i.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> shutil <span class="keyword">import</span> copy, rmtree</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mk_file</span>(<span class="params">file_path: <span class="built_in">str</span></span>):</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(file_path):</span><br><span class="line">        <span class="comment"># 如果文件夹存在，则先删除原文件夹在重新创建</span></span><br><span class="line">        rmtree(file_path)</span><br><span class="line">    os.makedirs(file_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="comment"># 保证随机可复现</span></span><br><span class="line">    random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将数据集中10%的数据划分到验证集中</span></span><br><span class="line">    split_rate = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 指向你解压后的flower_photos文件夹</span></span><br><span class="line">    cwd = os.getcwd()</span><br><span class="line">    </span><br><span class="line">    origin_flower_path = <span class="string">&quot;photos&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(origin_flower_path)</span><br><span class="line">    flower_class = [cla <span class="keyword">for</span> cla <span class="keyword">in</span> os.listdir(origin_flower_path)</span><br><span class="line">                    <span class="keyword">if</span> os.path.isdir(os.path.join(origin_flower_path, cla))]</span><br><span class="line"></span><br><span class="line">    data_root = os.path.join(cwd, <span class="string">&quot;dataset&quot;</span>)             </span><br><span class="line">    <span class="comment"># 建立保存训练集的文件夹</span></span><br><span class="line">    train_root = os.path.join(data_root, <span class="string">&quot;train&quot;</span>)</span><br><span class="line">    mk_file(train_root)</span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        <span class="comment"># 建立每个类别对应的文件夹</span></span><br><span class="line">        mk_file(os.path.join(train_root, cla))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 建立保存验证集的文件夹</span></span><br><span class="line">    val_root = os.path.join(data_root, <span class="string">&quot;val&quot;</span>)</span><br><span class="line">    mk_file(val_root)</span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        <span class="comment"># 建立每个类别对应的文件夹</span></span><br><span class="line">        mk_file(os.path.join(val_root, cla))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> cla <span class="keyword">in</span> flower_class:</span><br><span class="line">        cla_path = os.path.join(origin_flower_path, cla)</span><br><span class="line">        images = os.listdir(cla_path)</span><br><span class="line">        num = <span class="built_in">len</span>(images)</span><br><span class="line">        <span class="comment"># 随机采样验证集的索引</span></span><br><span class="line">        eval_index = random.sample(images, k=<span class="built_in">int</span>(num*split_rate))</span><br><span class="line">        <span class="keyword">for</span> index, image <span class="keyword">in</span> <span class="built_in">enumerate</span>(images):</span><br><span class="line">            <span class="keyword">if</span> image <span class="keyword">in</span> eval_index:</span><br><span class="line">                <span class="comment"># 将分配至验证集中的文件复制到相应目录</span></span><br><span class="line">                image_path = os.path.join(cla_path, image)</span><br><span class="line">                new_path = os.path.join(val_root, cla)</span><br><span class="line">                copy(image_path, new_path)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 将分配至训练集中的文件复制到相应目录</span></span><br><span class="line">                image_path = os.path.join(cla_path, image)</span><br><span class="line">                new_path = os.path.join(train_root, cla)</span><br><span class="line">                copy(image_path, new_path)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;\r[&#123;&#125;] processing [&#123;&#125;/&#123;&#125;]&quot;</span>.<span class="built_in">format</span>(cla, index+<span class="number">1</span>, num), end=<span class="string">&quot;&quot;</span>)  <span class="comment"># processing bar</span></span><br><span class="line">        <span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;processing done!&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="单张图片预测"><a href="#单张图片预测" class="headerlink" title="单张图片预测"></a>单张图片预测</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> AlexNet_v1, AlexNet_v2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    im_height = <span class="number">64</span></span><br><span class="line">    im_width = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img_path = <span class="string">&quot;../tulip.jpg&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(img_path)</span><br><span class="line">    img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># resize image to 64x64</span></span><br><span class="line">    img = img.resize((im_width, im_height))</span><br><span class="line">    plt.imshow(img)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># scaling pixel value to (0-1)</span></span><br><span class="line">    img = np.array(img) / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Add the image to a batch where it&#x27;s the only member.</span></span><br><span class="line">    img = (np.expand_dims(img, <span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># read class_indict</span></span><br><span class="line">    json_path = <span class="string">&#x27;./class_indices.json&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(json_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(json_path)</span><br><span class="line"></span><br><span class="line">    json_file = <span class="built_in">open</span>(json_path, <span class="string">&quot;r&quot;</span>)</span><br><span class="line">    class_indict = json.load(json_file)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># create model</span></span><br><span class="line">    model = AlexNet_v1(num_classes=<span class="number">5</span>)</span><br><span class="line">    weighs_path = <span class="string">&quot;./save_weights/myAlex.h5&quot;</span></span><br><span class="line">    <span class="keyword">assert</span> os.path.exists(img_path), <span class="string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="built_in">format</span>(weighs_path)</span><br><span class="line">    model.load_weights(weighs_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># prediction</span></span><br><span class="line">    result = np.squeeze(model.predict(img))</span><br><span class="line">    predict_class = np.argmax(result)</span><br><span class="line"></span><br><span class="line">    print_res = <span class="string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="built_in">format</span>(class_indict[<span class="built_in">str</span>(predict_class)],</span><br><span class="line">                                                 result[predict_class])</span><br><span class="line">    plt.title(print_res)</span><br><span class="line">    <span class="built_in">print</span>(print_res)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="常见的网络"><a href="#常见的网络" class="headerlink" title="常见的网络"></a>常见的网络</h1><h2 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h2><p><img src="https://wx1.sinaimg.cn/mw1024/007BSstUgy1gn3ad3hfp9j31a70m913n.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">np.set_printoptions(threshold=np.inf)</span><br><span class="line"></span><br><span class="line">cifar10 = tf.keras.datasets.cifar10</span><br><span class="line">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LeNet5</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LeNet5, self).__init__()</span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                         activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.c2 = Conv2D(filters=<span class="number">16</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">                         activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.p2 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">120</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">84</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line">        self.f3 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.c1(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line"></span><br><span class="line">        x = self.c2(x)</span><br><span class="line">        x = self.p2(x)</span><br><span class="line"></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.f1(x)</span><br><span class="line">        x = self.f2(x)</span><br><span class="line">        y = self.f3(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = LeNet5()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/LeNet5.ckpt&quot;</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line"></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>,</span><br><span class="line">                    callbacks=[cp_callback])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(model.trainable_variables)</span></span><br><span class="line">file = <span class="built_in">open</span>(<span class="string">&#x27;./weights.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> model.trainable_variables:</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.name) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.shape) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.numpy()) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">###############################################    show   ###############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练集和验证集的acc和loss曲线</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.plot(val_acc, label=<span class="string">&#x27;Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(val_loss, label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p><img src="https://wx4.sinaimg.cn/mw1024/007BSstUgy1gn3dkddg40j31hc0ock3s.jpg"></p>
<p><img src="https://wx4.sinaimg.cn/mw1024/007BSstUgy1gn3o0othswj31hc0u01hf.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">np.set_printoptions(threshold=np.inf)</span><br><span class="line"></span><br><span class="line">cifar10 = tf.keras.datasets.cifar10</span><br><span class="line">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet8</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(AlexNet8, self).__init__()</span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">96</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">        self.b1 = BatchNormalization()</span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.c2 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line">        self.b2 = BatchNormalization()</span><br><span class="line">        self.a2 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p2 = MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.c3 = Conv2D(filters=<span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                         activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                         </span><br><span class="line">        self.c4 = Conv2D(filters=<span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                         activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">                         </span><br><span class="line">        self.c5 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                         activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p3 = MaxPool2D(pool_size=(<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">2048</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d1 = Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">2048</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d2 = Dropout(<span class="number">0.5</span>)</span><br><span class="line">        self.f3 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.c1(x)</span><br><span class="line">        x = self.b1(x)</span><br><span class="line">        x = self.a1(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line"></span><br><span class="line">        x = self.c2(x)</span><br><span class="line">        x = self.b2(x)</span><br><span class="line">        x = self.a2(x)</span><br><span class="line">        x = self.p2(x)</span><br><span class="line"></span><br><span class="line">        x = self.c3(x)</span><br><span class="line"></span><br><span class="line">        x = self.c4(x)</span><br><span class="line"></span><br><span class="line">        x = self.c5(x)</span><br><span class="line">        x = self.p3(x)</span><br><span class="line"></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.f1(x)</span><br><span class="line">        x = self.d1(x)</span><br><span class="line">        x = self.f2(x)</span><br><span class="line">        x = self.d2(x)</span><br><span class="line">        y = self.f3(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = AlexNet8()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/AlexNet8.ckpt&quot;</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line"></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>,</span><br><span class="line">                    callbacks=[cp_callback])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(model.trainable_variables)</span></span><br><span class="line">file = <span class="built_in">open</span>(<span class="string">&#x27;./weights.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> model.trainable_variables:</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.name) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.shape) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.numpy()) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">###############################################    show   ###############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练集和验证集的acc和loss曲线</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.plot(val_acc, label=<span class="string">&#x27;Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(val_loss, label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h2><p><img src="https://wx2.sinaimg.cn/mw1024/007BSstUgy1gn3obmzy8fj31hc0u0e81.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">np.set_printoptions(threshold=np.inf)</span><br><span class="line"></span><br><span class="line">cifar10 = tf.keras.datasets.cifar10</span><br><span class="line">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGG16</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(VGG16, self).__init__()</span><br><span class="line">        self.c1 = Conv2D(filters=<span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)  <span class="comment"># 卷积层1</span></span><br><span class="line">        self.b1 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c2 = Conv2D(filters=<span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>, )</span><br><span class="line">        self.b2 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a2 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.p1 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d1 = Dropout(<span class="number">0.2</span>)  <span class="comment"># dropout层</span></span><br><span class="line"></span><br><span class="line">        self.c3 = Conv2D(filters=<span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b3 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a3 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c4 = Conv2D(filters=<span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b4 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a4 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.p2 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d2 = Dropout(<span class="number">0.2</span>)  <span class="comment"># dropout层</span></span><br><span class="line"></span><br><span class="line">        self.c5 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b5 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a5 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c6 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b6 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a6 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c7 = Conv2D(filters=<span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b7 = BatchNormalization()</span><br><span class="line">        self.a7 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p3 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d3 = Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        self.c8 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b8 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a8 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c9 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b9 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a9 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c10 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b10 = BatchNormalization()</span><br><span class="line">        self.a10 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p4 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d4 = Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        self.c11 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b11 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a11 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c12 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b12 = BatchNormalization()  <span class="comment"># BN层1</span></span><br><span class="line">        self.a12 = Activation(<span class="string">&#x27;relu&#x27;</span>)  <span class="comment"># 激活层1</span></span><br><span class="line">        self.c13 = Conv2D(filters=<span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.b13 = BatchNormalization()</span><br><span class="line">        self.a13 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.p5 = MaxPool2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>), strides=<span class="number">2</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.d5 = Dropout(<span class="number">0.2</span>)</span><br><span class="line"></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.f1 = Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d6 = Dropout(<span class="number">0.2</span>)</span><br><span class="line">        self.f2 = Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d7 = Dropout(<span class="number">0.2</span>)</span><br><span class="line">        self.f3 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.c1(x)</span><br><span class="line">        x = self.b1(x)</span><br><span class="line">        x = self.a1(x)</span><br><span class="line">        x = self.c2(x)</span><br><span class="line">        x = self.b2(x)</span><br><span class="line">        x = self.a2(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line">        x = self.d1(x)</span><br><span class="line"></span><br><span class="line">        x = self.c3(x)</span><br><span class="line">        x = self.b3(x)</span><br><span class="line">        x = self.a3(x)</span><br><span class="line">        x = self.c4(x)</span><br><span class="line">        x = self.b4(x)</span><br><span class="line">        x = self.a4(x)</span><br><span class="line">        x = self.p2(x)</span><br><span class="line">        x = self.d2(x)</span><br><span class="line"></span><br><span class="line">        x = self.c5(x)</span><br><span class="line">        x = self.b5(x)</span><br><span class="line">        x = self.a5(x)</span><br><span class="line">        x = self.c6(x)</span><br><span class="line">        x = self.b6(x)</span><br><span class="line">        x = self.a6(x)</span><br><span class="line">        x = self.c7(x)</span><br><span class="line">        x = self.b7(x)</span><br><span class="line">        x = self.a7(x)</span><br><span class="line">        x = self.p3(x)</span><br><span class="line">        x = self.d3(x)</span><br><span class="line"></span><br><span class="line">        x = self.c8(x)</span><br><span class="line">        x = self.b8(x)</span><br><span class="line">        x = self.a8(x)</span><br><span class="line">        x = self.c9(x)</span><br><span class="line">        x = self.b9(x)</span><br><span class="line">        x = self.a9(x)</span><br><span class="line">        x = self.c10(x)</span><br><span class="line">        x = self.b10(x)</span><br><span class="line">        x = self.a10(x)</span><br><span class="line">        x = self.p4(x)</span><br><span class="line">        x = self.d4(x)</span><br><span class="line"></span><br><span class="line">        x = self.c11(x)</span><br><span class="line">        x = self.b11(x)</span><br><span class="line">        x = self.a11(x)</span><br><span class="line">        x = self.c12(x)</span><br><span class="line">        x = self.b12(x)</span><br><span class="line">        x = self.a12(x)</span><br><span class="line">        x = self.c13(x)</span><br><span class="line">        x = self.b13(x)</span><br><span class="line">        x = self.a13(x)</span><br><span class="line">        x = self.p5(x)</span><br><span class="line">        x = self.d5(x)</span><br><span class="line"></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.f1(x)</span><br><span class="line">        x = self.d6(x)</span><br><span class="line">        x = self.f2(x)</span><br><span class="line">        x = self.d7(x)</span><br><span class="line">        y = self.f3(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = VGG16()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/VGG16.ckpt&quot;</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line"></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>,</span><br><span class="line">                    callbacks=[cp_callback])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(model.trainable_variables)</span></span><br><span class="line">file = <span class="built_in">open</span>(<span class="string">&#x27;./weights.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> model.trainable_variables:</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.name) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.shape) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.numpy()) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">###############################################    show   ###############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练集和验证集的acc和loss曲线</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.plot(val_acc, label=<span class="string">&#x27;Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(val_loss, label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="InceptionNet"><a href="#InceptionNet" class="headerlink" title="InceptionNet"></a>InceptionNet</h2><p><img src="https://wx1.sinaimg.cn/mw1024/007BSstUgy1gn3ojszn3yj31hc0u0to8.jpg"></p>
<p><img src="https://wx4.sinaimg.cn/mw1024/007BSstUgy1gn3oqigxyhj31gd0rb1fj.jpg"></p>
<p><img src="https://wx1.sinaimg.cn/mw1024/007BSstUgy1gn3os7ve8lj31hc0s5av2.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense, \</span><br><span class="line">    GlobalAveragePooling2D</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">np.set_printoptions(threshold=np.inf)</span><br><span class="line"></span><br><span class="line">cifar10 = tf.keras.datasets.cifar10</span><br><span class="line">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBNRelu</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ch, kernelsz=<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ConvBNRelu, self).__init__()</span><br><span class="line">        self.model = tf.keras.models.Sequential([</span><br><span class="line">            Conv2D(ch, kernelsz, strides=strides, padding=padding),</span><br><span class="line">            BatchNormalization(),</span><br><span class="line">            Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model(x, training=<span class="literal">False</span>) <span class="comment">#在training=False时，BN通过整个训练集计算均值、方差去做批归一化，training=True时，通过当前batch的均值、方差去做批归一化。推理时 training=False效果好</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InceptionBlk</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ch, strides=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(InceptionBlk, self).__init__()</span><br><span class="line">        self.ch = ch</span><br><span class="line">        self.strides = strides</span><br><span class="line">        self.c1 = ConvBNRelu(ch, kernelsz=<span class="number">1</span>, strides=strides)</span><br><span class="line">        self.c2_1 = ConvBNRelu(ch, kernelsz=<span class="number">1</span>, strides=strides)</span><br><span class="line">        self.c2_2 = ConvBNRelu(ch, kernelsz=<span class="number">3</span>, strides=<span class="number">1</span>)</span><br><span class="line">        self.c3_1 = ConvBNRelu(ch, kernelsz=<span class="number">1</span>, strides=strides)</span><br><span class="line">        self.c3_2 = ConvBNRelu(ch, kernelsz=<span class="number">5</span>, strides=<span class="number">1</span>)</span><br><span class="line">        self.p4_1 = MaxPool2D(<span class="number">3</span>, strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">        self.c4_2 = ConvBNRelu(ch, kernelsz=<span class="number">1</span>, strides=strides)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x1 = self.c1(x)</span><br><span class="line">        x2_1 = self.c2_1(x)</span><br><span class="line">        x2_2 = self.c2_2(x2_1)</span><br><span class="line">        x3_1 = self.c3_1(x)</span><br><span class="line">        x3_2 = self.c3_2(x3_1)</span><br><span class="line">        x4_1 = self.p4_1(x)</span><br><span class="line">        x4_2 = self.c4_2(x4_1)</span><br><span class="line">        <span class="comment"># concat along axis=channel</span></span><br><span class="line">        x = tf.concat([x1, x2_2, x3_2, x4_2], axis=<span class="number">3</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Inception10</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_blocks, num_classes, init_ch=<span class="number">16</span>, **kwargs</span>):</span><br><span class="line">        <span class="built_in">super</span>(Inception10, self).__init__(**kwargs)</span><br><span class="line">        self.in_channels = init_ch</span><br><span class="line">        self.out_channels = init_ch</span><br><span class="line">        self.num_blocks = num_blocks</span><br><span class="line">        self.init_ch = init_ch</span><br><span class="line">        self.c1 = ConvBNRelu(init_ch)</span><br><span class="line">        self.blocks = tf.keras.models.Sequential()</span><br><span class="line">        <span class="keyword">for</span> block_id <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">            <span class="keyword">for</span> layer_id <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">                <span class="keyword">if</span> layer_id == <span class="number">0</span>:</span><br><span class="line">                    block = InceptionBlk(self.out_channels, strides=<span class="number">2</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    block = InceptionBlk(self.out_channels, strides=<span class="number">1</span>)</span><br><span class="line">                self.blocks.add(block)</span><br><span class="line">            <span class="comment"># enlarger out_channels per block</span></span><br><span class="line">            self.out_channels *= <span class="number">2</span></span><br><span class="line">        self.p1 = GlobalAveragePooling2D()</span><br><span class="line">        self.f1 = Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.c1(x)</span><br><span class="line">        x = self.blocks(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line">        y = self.f1(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Inception10(num_blocks=<span class="number">2</span>, num_classes=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/Inception10.ckpt&quot;</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line"></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>,</span><br><span class="line">                    callbacks=[cp_callback])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(model.trainable_variables)</span></span><br><span class="line">file = <span class="built_in">open</span>(<span class="string">&#x27;./weights.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> model.trainable_variables:</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.name) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.shape) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.numpy()) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">###############################################    show   ###############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练集和验证集的acc和loss曲线</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.plot(val_acc, label=<span class="string">&#x27;Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(val_loss, label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><p><img src="https://wx2.sinaimg.cn/mw1024/007BSstUgy1gn3p387l8wj31hc0u04hs.jpg"></p>
<p><img src="https://wx3.sinaimg.cn/mw1024/007BSstUgy1gn3p6slbzjj31hc0u04qp.jpg"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">np.set_printoptions(threshold=np.inf)</span><br><span class="line"></span><br><span class="line">cifar10 = tf.keras.datasets.cifar10</span><br><span class="line">(x_train, y_train), (x_test, y_test) = cifar10.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResnetBlock</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, filters, strides=<span class="number">1</span>, residual_path=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResnetBlock, self).__init__()</span><br><span class="line">        self.filters = filters</span><br><span class="line">        self.strides = strides</span><br><span class="line">        self.residual_path = residual_path</span><br><span class="line"></span><br><span class="line">        self.c1 = Conv2D(filters, (<span class="number">3</span>, <span class="number">3</span>), strides=strides, padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.b1 = BatchNormalization()</span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.c2 = Conv2D(filters, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.b2 = BatchNormalization()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># residual_path为True时，对输入进行下采样，即用1x1的卷积核做卷积操作，保证x能和F(x)维度相同，顺利相加</span></span><br><span class="line">        <span class="keyword">if</span> residual_path:</span><br><span class="line">            self.down_c1 = Conv2D(filters, (<span class="number">1</span>, <span class="number">1</span>), strides=strides, padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">            self.down_b1 = BatchNormalization()</span><br><span class="line">        </span><br><span class="line">        self.a2 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        residual = inputs  <span class="comment"># residual等于输入值本身，即residual=x</span></span><br><span class="line">        <span class="comment"># 将输入通过卷积、BN层、激活层，计算F(x)</span></span><br><span class="line">        x = self.c1(inputs)</span><br><span class="line">        x = self.b1(x)</span><br><span class="line">        x = self.a1(x)</span><br><span class="line"></span><br><span class="line">        x = self.c2(x)</span><br><span class="line">        y = self.b2(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.residual_path:</span><br><span class="line">            residual = self.down_c1(inputs)</span><br><span class="line">            residual = self.down_b1(residual)</span><br><span class="line"></span><br><span class="line">        out = self.a2(y + residual)  <span class="comment"># 最后输出的是两部分的和，即F(x)+x或F(x)+Wx,再过激活函数</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet18</span>(<span class="title class_ inherited__">Model</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block_list, initial_filters=<span class="number">64</span></span>):  <span class="comment"># block_list表示每个block有几个卷积层</span></span><br><span class="line">        <span class="built_in">super</span>(ResNet18, self).__init__()</span><br><span class="line">        self.num_blocks = <span class="built_in">len</span>(block_list)  <span class="comment"># 共有几个block</span></span><br><span class="line">        self.block_list = block_list</span><br><span class="line">        self.out_filters = initial_filters</span><br><span class="line">        self.c1 = Conv2D(self.out_filters, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&#x27;same&#x27;</span>, use_bias=<span class="literal">False</span>)</span><br><span class="line">        self.b1 = BatchNormalization()</span><br><span class="line">        self.a1 = Activation(<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.blocks = tf.keras.models.Sequential()</span><br><span class="line">        <span class="comment"># 构建ResNet网络结构</span></span><br><span class="line">        <span class="keyword">for</span> block_id <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(block_list)):  <span class="comment"># 第几个resnet block</span></span><br><span class="line">            <span class="keyword">for</span> layer_id <span class="keyword">in</span> <span class="built_in">range</span>(block_list[block_id]):  <span class="comment"># 第几个卷积层</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> block_id != <span class="number">0</span> <span class="keyword">and</span> layer_id == <span class="number">0</span>:  <span class="comment"># 对除第一个block以外的每个block的输入进行下采样</span></span><br><span class="line">                    block = ResnetBlock(self.out_filters, strides=<span class="number">2</span>, residual_path=<span class="literal">True</span>)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    block = ResnetBlock(self.out_filters, residual_path=<span class="literal">False</span>)</span><br><span class="line">                self.blocks.add(block)  <span class="comment"># 将构建好的block加入resnet</span></span><br><span class="line">            self.out_filters *= <span class="number">2</span>  <span class="comment"># 下一个block的卷积核数是上一个block的2倍</span></span><br><span class="line">        self.p1 = tf.keras.layers.GlobalAveragePooling2D()</span><br><span class="line">        self.f1 = tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        x = self.c1(inputs)</span><br><span class="line">        x = self.b1(x)</span><br><span class="line">        x = self.a1(x)</span><br><span class="line">        x = self.blocks(x)</span><br><span class="line">        x = self.p1(x)</span><br><span class="line">        y = self.f1(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = ResNet18([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">checkpoint_save_path = <span class="string">&quot;./checkpoint/ResNet18.ckpt&quot;</span></span><br><span class="line"><span class="keyword">if</span> os.path.exists(checkpoint_save_path + <span class="string">&#x27;.index&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-------------load the model-----------------&#x27;</span>)</span><br><span class="line">    model.load_weights(checkpoint_save_path)</span><br><span class="line"></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 save_best_only=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>,</span><br><span class="line">                    callbacks=[cp_callback])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(model.trainable_variables)</span></span><br><span class="line">file = <span class="built_in">open</span>(<span class="string">&#x27;./weights.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> model.trainable_variables:</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.name) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.shape) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    file.write(<span class="built_in">str</span>(v.numpy()) + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">file.close()</span><br><span class="line"></span><br><span class="line"><span class="comment">###############################################    show   ###############################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示训练集和验证集的acc和loss曲线</span></span><br><span class="line">acc = history.history[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">val_acc = history.history[<span class="string">&#x27;val_sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">loss = history.history[<span class="string">&#x27;loss&#x27;</span>]</span><br><span class="line">val_loss = history.history[<span class="string">&#x27;val_loss&#x27;</span>]</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(acc, label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.plot(val_acc, label=<span class="string">&#x27;Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.plot(loss, label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(val_loss, label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="https://wx3.sinaimg.cn/mw1024/007BSstUgy1gn3qwpz1qfj316b0pee48.jpg"></p>
<h1 id="TensorBoard可视化"><a href="#TensorBoard可视化" class="headerlink" title="TensorBoard可视化"></a>TensorBoard可视化</h1><p>代码中加上这一段</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##保存训练过程</span></span><br><span class="line">logdir = os.path.join(<span class="string">&#x27;logs&#x27;</span>)<span class="comment">#win10下的bug，</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(logdir):</span><br><span class="line">    os.makedirs(logdir)</span><br><span class="line">output_model_file = os.path.join(logdir,<span class="string">&#x27;models.ckpt&#x27;</span>)</span><br><span class="line">callbacks = [</span><br><span class="line">    keras.callbacks.TensorBoard(logdir),</span><br><span class="line">    keras.callbacks.ModelCheckpoint(output_model_file, monitor=<span class="string">&#x27;val_loss&#x27;</span>, verbose=<span class="number">0</span>, save_best_only=<span class="literal">True</span>, save_weights_only=<span class="literal">True</span>, mode=<span class="string">&#x27;auto&#x27;</span>, period=<span class="number">1</span>),</span><br><span class="line">    <span class="comment">#keras.callbacks.EarlyStopping(patience=5,min_delta=1e-3)</span></span><br><span class="line">]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>在model.fit()中加上callbacks&#x3D;callbacks，例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">history = model.fit(x=train_data_gen,</span><br><span class="line">                    steps_per_epoch=total_train // batch_size,</span><br><span class="line">                    epochs=epochs,</span><br><span class="line">                    validation_data=val_data_gen,</span><br><span class="line">                    validation_steps=total_val // batch_size,</span><br><span class="line">                    callbacks=callbacks)</span><br></pre></td></tr></table></figure>



<p><strong>How to use TensorBoard？</strong></p>
<p>（1）在anaconda中激活你所使用的python版本，例如：activate tensorflow2</p>
<p><img src="https://wx1.sinaimg.cn/mw1024/007BSstUgy1gna7asdhnhj30kv04uaa6.jpg"></p>
<p>（2）定位到指定路径</p>
<p><img src="https://wx4.sinaimg.cn/mw1024/007BSstUgy1gna7bznfyij30ld06haag.jpg"></p>
<p>（3）输入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir logs</span><br></pre></td></tr></table></figure>



<p>（4）得到</p>
<p><img src="https://wx2.sinaimg.cn/mw1024/007BSstUgy1gna7eg7bk9j30mz011t8m.jpg"></p>
<p>复制该网址在浏览器打开</p>
<p>备注：如果无法打开</p>
<p><img src="https://wx4.sinaimg.cn/mw1024/007BSstUgy1gna7hgtzm1j30cy0awq3d.jpg"></p>
<p>在浏览器输入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">localhost:<span class="number">6006</span></span><br></pre></td></tr></table></figure>

<p>即可：</p>
<p><img src="https://wx2.sinaimg.cn/mw1024/007BSstUgy1gnaf37g68oj30q10guac2.jpg"></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/05/!%E6%A8%A1%E6%9D%BF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="unique_Hang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="unique_Hang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/05/!%E6%A8%A1%E6%9D%BF/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-05 14:46:27" itemprop="dateCreated datePublished" datetime="2022-04-05T14:46:27+08:00">2022-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-06 14:22:59" itemprop="dateModified" datetime="2022-04-06T14:22:59+08:00">2022-04-06</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <meta name="referrer" content="no-referrer" /> 

<p>Welcome to unique_Hang’s blog.</p>
<blockquote>
<p><strong>鲁迅说过：看unique_Hang博客的人颜值都很高！</strong>  </p>
<p>打不开图片可以鼠标右键点击“复制图片地址”在新窗口中打开<br>作者邮箱：<a href="mailto:&#117;&#x6e;&#x69;&#x71;&#x75;&#x65;&#95;&#104;&#97;&#110;&#x67;&#x40;&#x71;&#113;&#x2e;&#x63;&#x6f;&#109;">&#117;&#x6e;&#x69;&#x71;&#x75;&#x65;&#95;&#104;&#97;&#110;&#x67;&#x40;&#x71;&#113;&#x2e;&#x63;&#x6f;&#109;</a><br>喜欢的小伙伴可以关注我的b站账号(<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">https://space.bilibili.com/290100464</a>)  </p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/05/%E3%80%90python%E5%AD%A6%E4%B9%A0%E3%80%91%E5%A6%82%E4%BD%95%E7%94%A8%E6%89%8B%E6%9C%BA%E8%BF%9C%E7%A8%8B%E6%8E%A7%E5%88%B6%E7%94%B5%E8%84%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="unique_Hang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="unique_Hang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/05/%E3%80%90python%E5%AD%A6%E4%B9%A0%E3%80%91%E5%A6%82%E4%BD%95%E7%94%A8%E6%89%8B%E6%9C%BA%E8%BF%9C%E7%A8%8B%E6%8E%A7%E5%88%B6%E7%94%B5%E8%84%91/" class="post-title-link" itemprop="url">【python学习】如何用手机远程控制电脑</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-05 11:53:19" itemprop="dateCreated datePublished" datetime="2022-04-05T11:53:19+08:00">2022-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-06 14:23:07" itemprop="dateModified" datetime="2022-04-06T14:23:07+08:00">2022-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%97%A5%E5%B8%B8/" itemprop="url" rel="index"><span itemprop="name">日常</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <meta name="referrer" content="no-referrer" /> 

<p>Welcome to unique_Hang’s blog.</p>
<blockquote>
<p><strong>鲁迅说过：看unique_Hang博客的人颜值都很高！</strong><br> 作者邮箱：<a href="mailto:unique_hang@qq.com">unique_hang@qq.com</a><br>喜欢的小伙伴可以关注我的<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">b站账号</a>(<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">https://space.bilibili.com/290100464</a>)  </p>
</blockquote>
<h2 id="思路讲解"><a href="#思路讲解" class="headerlink" title="思路讲解"></a>思路讲解</h2><p>通过python的PyAutoGui函数实现，官方文档链接：<br><a target="_blank" rel="noopener" href="https://pyautogui.readthedocs.io/en/latest/msgbox.html">https://pyautogui.readthedocs.io/en/latest/msgbox.html</a><br>该库提供图片识别定位、鼠标操作、键盘操作函数。<br>通过QQ或微信的远程助手辅助手机控制电脑。</p>
<h2 id="这是我在bilibili发布的视频"><a href="#这是我在bilibili发布的视频" class="headerlink" title="这是我在bilibili发布的视频"></a>这是我在bilibili发布的视频</h2><iframe src="//player.bilibili.com/player.html?aid=497606390&bvid=BV15K411L7m7&cid=174010751&page=1" scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>

<p>感兴趣的小伙伴可以在bilibili私信我，互相交流学习~</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/05/%E5%B8%B8%E7%94%A8%E7%BD%91%E7%AB%99%E5%88%86%E4%BA%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="unique_Hang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="unique_Hang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/05/%E5%B8%B8%E7%94%A8%E7%BD%91%E7%AB%99%E5%88%86%E4%BA%AB/" class="post-title-link" itemprop="url">常用网站分享</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-05 11:49:24" itemprop="dateCreated datePublished" datetime="2022-04-05T11:49:24+08:00">2022-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-06 14:25:50" itemprop="dateModified" datetime="2022-04-06T14:25:50+08:00">2022-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%97%A5%E5%B8%B8/" itemprop="url" rel="index"><span itemprop="name">日常</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <meta name="referrer" content="no-referrer" /> 

<p>Welcome to unique_Hang’s blog.</p>
<blockquote>
<p><strong>鲁迅说过：看unique_Hang博客的人颜值都很高！</strong><br> 作者邮箱：<a href="mailto:unique_hang@qq.com">unique_hang@qq.com</a><br>喜欢的小伙伴可以关注我的<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">b站账号</a>(<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">https://space.bilibili.com/290100464</a>)  </p>
</blockquote>
<h2 id="Markdown在线编辑：http-marxi-co"><a href="#Markdown在线编辑：http-marxi-co" class="headerlink" title="Markdown在线编辑：http://marxi.co/"></a>Markdown在线编辑：<a target="_blank" rel="noopener" href="http://marxi.co/">http://marxi.co/</a></h2><p>可在该可视化网站预先浏览Markdown编写布局<br><img src="https://i.loli.net/2020/04/07/lj7nDbasId5TGBN.png" alt="1.png"></p>
<h2 id="图床：https-sm-ms"><a href="#图床：https-sm-ms" class="headerlink" title="图床：https://sm.ms/"></a>图床：<a target="_blank" rel="noopener" href="https://sm.ms/">https://sm.ms/</a></h2><p>上传图片提供访问链接，用于博客插图<br><img src="https://i.loli.net/2020/04/07/Lws4pr1Wec8B6my.png" alt="2.png"></p>
<h2 id="视频片头制作：https-panzoid-com"><a href="#视频片头制作：https-panzoid-com" class="headerlink" title="视频片头制作：https://panzoid.com/"></a>视频片头制作：<a target="_blank" rel="noopener" href="https://panzoid.com/">https://panzoid.com/</a></h2><p>找一个模板、点击左侧的正方体、修改里面text文本，插入中文需要点击custom文体自己添加<br><img src="https://i.loli.net/2020/04/08/NsZRBlu9MYk3XqD.png" alt="666.png"></p>
<h2 id="百度云搜索：https-wowenda-com"><a href="#百度云搜索：https-wowenda-com" class="headerlink" title="百度云搜索：https://wowenda.com/"></a>百度云搜索：<a target="_blank" rel="noopener" href="https://wowenda.com/">https://wowenda.com/</a></h2><p>搜索百度云盘分享<br><img src="https://i.loli.net/2020/04/07/XLeJDSUvol1R6m4.png" alt="3.png"></p>
<h2 id=""><a href="#" class="headerlink" title=""></a></h2><p>PPT模板下载：<a target="_blank" rel="noopener" href="http://www.ypppt.com/?utm_source=qq&utm_medium=social&utm_oi=893907464297254912">http://www.ypppt.com/?utm_source&#x3D;qq&amp;utm_medium&#x3D;social&amp;utm_oi&#x3D;893907464297254912</a></p>
<p>下载免费PPT模板<br><img src="https://i.loli.net/2020/04/07/xyd2wuk5UpAmzjl.png" alt="42432.png"></p>
<h2 id="图片处理网站："><a href="#图片处理网站：" class="headerlink" title="图片处理网站："></a>图片处理网站：</h2><p>照片去码（扣除人物）：<a target="_blank" rel="noopener" href="https://www.nvidia.com/research/inpainting/">https://www.nvidia.com/research/inpainting/</a><br>通过鼠标涂抹mask（涂抹马赛克范围就是去码，涂抹一个人就是扣除人物）<br><img src="https://i.loli.net/2020/04/24/WuHM7cmBP8ps9R4.png" alt="_WW@_AGBA_FCLM2Z2SFKQ_E.png"><br><img src="https://i.loli.net/2020/04/24/bwzlOyAB8VagFtJ.png" alt="_RC_O_N8WCX0B_ELD3IUGU6.png"><br>![&#96;VRZBI~Y4_1G__8A_AW_8S6.png]()<br><img src="https://i.loli.net/2020/04/24/8lFJ6MRrnSfaD32.png" alt="L8_LCZVE4BML1CYJU_3VNO5.png"><br>配合图片放大网站：<a target="_blank" rel="noopener" href="https://bigjpg.com/">https://bigjpg.com/</a><br>快速换脸：<a target="_blank" rel="noopener" href="https://reflect.tech/faceswap/hot">https://reflect.tech/faceswap/hot</a></p>
<h2 id="英语听力学习网址：youzack-com"><a href="#英语听力学习网址：youzack-com" class="headerlink" title="英语听力学习网址：youzack.com"></a>英语听力学习网址：youzack.com</h2><h2 id="廖雪峰python学习：https-www-liaoxuefeng-com-wiki-1016959663602400"><a href="#廖雪峰python学习：https-www-liaoxuefeng-com-wiki-1016959663602400" class="headerlink" title="廖雪峰python学习：https://www.liaoxuefeng.com/wiki/1016959663602400"></a>廖雪峰python学习：<a target="_blank" rel="noopener" href="https://www.liaoxuefeng.com/wiki/1016959663602400">https://www.liaoxuefeng.com/wiki/1016959663602400</a></h2><p>学习python<br><img src="https://i.loli.net/2020/04/07/UvPWMYlhXuBfJT3.png" alt="5.png"></p>
<h2 id="-1"><a href="#-1" class="headerlink" title=""></a></h2><p>正点原子STM32学习视频：<a target="_blank" rel="noopener" href="https://space.bilibili.com/394620890?from=search&seid=59432885784523843">https://space.bilibili.com/394620890?from=search&seid=59432885784523843</a></p>
<p>学习STM32<br><img src="https://i.loli.net/2020/04/07/hJTSLAucpDNrBdZ.png" alt="6.png"></p>
<h2 id="免费看电影网站：https-www-libvio-com"><a href="#免费看电影网站：https-www-libvio-com" class="headerlink" title="免费看电影网站：https://www.libvio.com/"></a>免费看电影网站：<a target="_blank" rel="noopener" href="https://www.libvio.com/">https://www.libvio.com/</a></h2><h2 id="在线p图网站：https-www-gaoding-com"><a href="#在线p图网站：https-www-gaoding-com" class="headerlink" title="在线p图网站：https://www.gaoding.com/"></a>在线p图网站：<a target="_blank" rel="noopener" href="https://www.gaoding.com/">https://www.gaoding.com/</a></h2><p>待更~  </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/05/win10%E7%B3%BB%E7%BB%9F%E7%94%A8hexo-GitHub%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="unique_Hang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="unique_Hang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/04/05/win10%E7%B3%BB%E7%BB%9F%E7%94%A8hexo-GitHub%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/" class="post-title-link" itemprop="url">win10系统用hexo+GitHub搭建博客遇到的坑</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-04-05 11:13:46" itemprop="dateCreated datePublished" datetime="2022-04-05T11:13:46+08:00">2022-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-04-06 14:25:07" itemprop="dateModified" datetime="2022-04-06T14:25:07+08:00">2022-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%97%A5%E5%B8%B8/" itemprop="url" rel="index"><span itemprop="name">日常</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <meta name="referrer" content="no-referrer" /> 

<p>Welcome to unique_Hang’s blog.</p>
<blockquote>
<p><strong>鲁迅说过：看unique_Hang博客的人颜值都很高！</strong><br> 作者邮箱：<a href="mailto:unique_hang@qq.com">unique_hang@qq.com</a><br>喜欢的小伙伴可以关注我的<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">b站账号</a>(<a target="_blank" rel="noopener" href="https://space.bilibili.com/290100464">https://space.bilibili.com/290100464</a>)  </p>
</blockquote>
<h2 id="1、repo配置报错"><a href="#1、repo配置报错" class="headerlink" title="1、repo配置报错"></a>1、repo配置报错</h2><p>网上很多搭建博客经验分享帖中repo配置写入的是HTTPS(形如:<a target="_blank" rel="noopener" href="https://github.com/">https://github.com/</a><br>XXXX&#x2F;XXXX.github.io.git格式)。win10系统运行时会报错。</p>
<p><strong>解决方法：</strong><br>win10系统repo需要写入SSH (形如:<br><a href="mailto:git@github.com">git@github.com</a>:仓库名&#x2F;用户名.github.io.git格式)。<br>例如我的仓库名&#x2F;用户名为<br><img src="https://i.loli.net/2020/04/07/rI5tCDHuxcPZRVG.png" alt="8.png"><br>我的repo配置:<br>repo: <a href="mailto:git@github.com">git@github.com</a>:day-day-up-<br>hang&#x2F;unique_Hang.github.io.git</p>
<h2 id="2、打开你的博客网址后显示404"><a href="#2、打开你的博客网址后显示404" class="headerlink" title="2、打开你的博客网址后显示404"></a>2、打开你的博客网址后显示404</h2><p><img src="https://i.loli.net/2020/04/07/1nZEHDbINT9Kujg.png" alt="2.png"><br>原因:你们没有选择自己的主题。<br> <strong>解决方法：</strong><br>进入github你的仓库<br><img src="https://i.loli.net/2020/04/07/PAujFrcoMkvRGIy.png" alt="3.png"><br>点击进入Settings后页面往下拉,看到GitHub Pages (你们应该没有绿色背景这行字)<br><img src="https://i.loli.net/2020/04/07/GOAsormgqDFTn3y.png" alt="4.png"><br>点击Choose a theme ,里面随便点一个主题后,点击select theme后出现<br>绿色背景这行字就表示成功。<br><img src="https://i.loli.net/2020/04/07/uBplk7bqeM1tXQz.png" alt="5.png"></p>
<h2 id="3、部署后不能显示主题样式"><a href="#3、部署后不能显示主题样式" class="headerlink" title="3、部署后不能显示主题样式"></a>3、部署后不能显示主题样式</h2><p>在本地看我的博客没有问题,如下图 :<br><img src="https://i.loli.net/2020/04/07/YXaupRdLNEP1zHC.png" alt="6.png"><br>但是部署到github上之后,无法显示主题,如下图 :<br><img src="https://i.loli.net/2020/04/07/WQaCruUEBMeqDdp.png" alt="7.png"><br> <strong>解决方法：</strong><br>更改一下_config.ymI文件的root属性。root后写你的用户名<br><img src="https://i.loli.net/2020/04/07/rI5tCDHuxcPZRVG.png" alt="8.png"><br>比如我的root: &#x2F;unique_Hang.github.io&#x2F;<br>设置完后删除目录下的 .deploy_git 那是生成的文件<br>在然后重新上传项目<br>hexo clean<br>hexo generate<br>hexo deploy<br>即可</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">unique_Hang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">28</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">unique_Hang</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
